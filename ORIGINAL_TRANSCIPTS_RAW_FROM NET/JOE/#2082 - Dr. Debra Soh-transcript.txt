0 (2s):
Joe Rogan podcast. Check out.

1 (4s):
The Joe Rogan Experience

2 (6s):
Train by day. Joe Rogan podcast by night. All day.

3 (12s):
Hello Good to see you. Hi. What's cracking? How you been?

4 (15s):
Thank you for having me back.

3 (17s):
My pleasure. It's been quite a while.

4 (18s):
It's so nice to see you I. know, the first time I did your show you were still in la which was That's right. Five years ago, if you can believe it.

3 (24s):
Is it really? Five years. Wow. Time flies.

4 (26s):
And then the last time I saw you was over Skype when my book came out. The End of Gender. That was 2020 before you came here.

3 (33s):
That's right. So how you been? I've been good. What are you working on? I

4 (37s):
Love Austin. So I'm working on a new project and I'm not ready to to announce exactly what it is yet, but I'm here to get your audience's feedback. Okay. 'cause I love hearing from people and I wanna know what's going on in people's lives and what their experiences are like. And I'd love to hear your perspective too, especially because you are the father of three girls. A lot of these issues I'm talking about have to do with young people, especially Generation Z and I. Guess I wanna start by, unless you wanna I have, I have a whole list of things I wanna talk about.

3 (1m 6s):
Talk to. Okay. No, let's go right into it.

4 (1m 8s):
Okay. So I know you appreciate all of the craziness that's been happening in academia in terms of the, I watched Yuri Beov I know you talk a lot about him and the defector. Yeah. and I feel like he must be, he must be psychic or something because what he describes in terms of ideological subversion and how to control basically an entire generation by going through academics and teaching them at a young age how to think, what to think more specifically, and how to then get people to a place where they can't agree on what objective reality is. That's essentially what's happening on university campuses. So for myself, having come through academia, finishing my PhD, realizing that I wouldn't be able to stay there and do legitimate research anymore.

4 (1m 55s):
And so I have to come on the, well, not, I have to come on the biggest podcast in the world. I'm very excited and grateful to be here, but I'm like, why don't I just do my own research and do it this way and not have to be con constrained by a particular way of thinking, or ha knowing I have to find certain things with my research in order for it to be published. And if it does get published, because, and it goes against what activists want you to say, it's gonna get pulled, your funding is gonna get pulled, you're gonna end up homeless anyway. So I'm Might as might as well just go straight from A to B.

3 (2m 25s):
The Yuri Beov of interview from I think it was 84 Yeah. Is so crazy because back then I'm sure people were like, come on, this is nonsense. Yeah. This is not. But if you look at it now, in 2023, like he was telling the truth. He has to have been telling the truth and that the Soviet Union had planned this out for generations, and that they knew that this was going to be a 10, 20, 30 year project. And it's been successful. And the fact that these academics, these people that we count on to think for us, we count on to be, you know, the shining light of intellectual discourse.

3 (3m 10s):
They have completely fallen captive to everything that he described. And that they are sending that out into the world. This mind virus and e essentially eroding all of our confidence in government, all our confidence in civil discourse, all of our confidence in our ability to get along and, and to, to understand objective reality is, it's crazy that what he was saying is exactly what happened.

4 (3m 40s):
It's pretty brilliant though, I have to say. The way that this has turned out for ideological people, if it's, if you're pushing that agenda and you've managed to convince an entire generation, because he was saying in the interview, it's gonna take 15, 20 years at least. Yeah. To clear out that way of thinking. Because when you go to university, and I can definitely relate to that. When you are young and you're impressionable, you don't stop and think maybe my professor is lying to me. Right. Or maybe my professor is trying to trick me into thinking of, in a very biased way, in a particular way, because they want to see certain changes in the world and this is how they've chosen to do it. So yeah, I I I guess they, they probably didn't know back in the 1980s that this is how it would unfold in terms of the internet and social media being so powerful in disseminating a particular way of thinking.

4 (4m 25s):
But it's been very, very effective. and I think, especially when you look at mental health, I know you're a big fan of John Heights work. I love his work as well. And you look at young people and how much they're struggling nowadays. And social media is a big part of that. So this new project I'm working on is really interested in looking at how do we get to this point, you know, how is technology influencing our lives and particularly our sex and dating lives, because I do think social media apps, what else? Like filters, I know you've talked about just everything in terms of how men and women relate to one another is almost completely upside down compared to, I would say even a decade ago. So one, one thing that really stood out to me in recent months is this adoption of something called a positionality statement.

4 (5m 5s):
I don know if you've heard of this before. No. So this is a statement now that researchers, including scientists, have to include in their research papers. and it basically discusses their race, their sex, gender identity, sexual orientation, socioeconomic status, all of their personal characteristics, traits, like basically identity markers as a way to, I guess, apologize if they're white, which is something white people should not have to do. Especially if you're in the sciences. You shouldn't have to talk anything about your personal life. Right. 'cause it has no bearing on what you're doing or what you find. It is so cringe worthy. It's, when I read these statements, it honestly feels like I'm reading a hostage statement.

4 (5m 48s):
I feel so sad for these people because especially if they're white, they're like this one guy, this poor kid. So usually it's in the context of a scientific paper that's being published. You know, the, the editor will say, we are now adopting this. You have to include this as part of your submission. And if you don't include it, they're probably not even gonna, they're probably just gonna throw your research in the trash when you submit it. But if you are a student, like you're doing a PhD or a master's, some schools will it force you to include this as part of your dissertation or thesis. So I can't imagine when you go to defend at the end, when you're finished all your research and you're basically presenting it and you're being interrogated, having to add this cringe-worthy statement. This one I read, it was this poor kid. He was saying, you know, I'm white. I'm from the us.

4 (6m 28s):
I have privilege in these ways. They went to, I think Africa to do their research there. So he was talking about how he might have been privileged over the people he was studying. And then he went on to describe this, the characteristics of his research partner who was also white. But he's saying she's a white woman who's from here and she had this, you know, socio socio socioeconomic status. and I just thought, this is so irrelevant. and it also so uncomfortable that you would have to talk about your colleague in this way. and I just can't believe that there are people who are actually on board with this. So to me, science is completely lost. I know how it's gonna come back from this because I think the public is already extremely skeptical as they should be. And so for me now I'm like, all right, I guess I'm going rogue and just doing my own thing.

3 (7m 7s):
Well a lot of journalists have found themselves in that same position too. Right? A lot of people have just gone to substack, people that were working for the New York Times and all these, you know, before very reputable institutions. And now they find themselves ideologically homeless.

4 (7m 23s):
Definitely I mean. So I, I'm a journalist now too, and I found the same thing that, you know, there were some left-leaning media platforms that I could write for very easily before when I, last time I was on your show. I just wanna clarify, 'cause I know a number of people quite upset with me when I said I was a liberal and I'm also pro-science. I'm definitely not saying that because someone is politically liberal or left-leaning that they are pro-science. Because definitely I think over the last three, four years we see what pros quote pro science means. So I think you can deny science regardless of where you are on the political spectrum. and I definitely my work for the most part, calls out, I'd say left-leaning science now because I think liberals are getting away with it the most right now because they have such a choke hold on the culture and are institutions more broadly.

4 (8m 5s):
Well,

3 (8m 5s):
The really disturbing thing is that they've abandoned the idea of what science is supposed to be. It's supposed to be objectively assessing data and looking at numbers and looking at measurements and looking at the, the reality of the situation and not putting everything through an ideological lens. And the fact that they're doing that first and that they have to list all their biases and like their privileges and all this different shit and their gender and all that craziness is just like, they're, they're essentially saying that that's more important than the objective truth. That's more important than the facts and the measurements and the data.

4 (8m 41s):
Also that they have such difficulty in calling out antisemitism. Because I was watching your podcast from yesterday, I think it was, and yeah, just I was, I'm just appalled, I'm appalled at, at the fact that you're in an environment where like there are students who are literally afraid. They're locking themselves in the library to try and be safe. This is not acceptable to me. It and, and the fact that you have speech codes that are designed to protect other groups, presumably, but yet groups that are doing well in society like Jewish and Asian people, we are considered white now. So it's okay to discriminate against us as you see with affirmative action and as you see what's happening right now in terms of the, the congress hearing. So I just don't know how academia's gonna come back. I've, at this point, I really have just said, okay, well I think we're gonna have to wait another 15, 20 years and hopefully alternatives will be built up and hopefully the public will see the value in science and education again one day.

3 (9m 32s):
Yeah. It's weird, right? The, the, the con the Congress hearings, they're so strange. It's so strange seeing these presidents of major universities that aren't just unwilling to call out antisemitism. They don't seem to have a problem with what these people are saying. And they, they seem to be trying to find some way to either apologize for it or just dismiss it. It's like to say that it has to be actionable when you're literally calling for death to the Jews.

4 (10m 5s):
Depends on the context. It's

3 (10m 7s):
Insane. And what kind of context? So ridiculous. Is that okay, what I mean? What when I mean when, when people in, you know, when I was in high school and we would look back on the Holocaust and we'd look back on World War II and you study it in school, it was always confusing. Like, how did this happen? How did anyone just decide that one group of people is okay to exterminate? And how are these like modern an anatomically similar human beings to the people that are living right now? Like when, you know, in the eighties when I was in high school and when we're thinking about this, this is only 40 years, which is so crazy. So we're literally talking about like as if something happened in the nineties today, which is so crazy.

3 (10m 51s):
It's so hard to imagine that like something from like 1989, like, or let's say when I was in high school, I graduated in 85. Imagine there was a Holocaust then, and we were trying to understand it in 2023. It's so recent. Like how, how did they do it? And then you see these professors or these teachers, these, these presidents of these universities, you go, oh, this isn't gonna away at all. This is like, we're still insane. We're still insane. And not just insane with like some meth smoking dictator who's in Germany. No, a fucking president of Harvard in 2023.

3 (11m 35s):
Like, what is happening? How is this possible? It it, I think it highlights for many people the, the, the giant difference between the real world and what kind of ideological subversion is going on in universities. 'cause I think for the most part, most people who, you know, are my age or younger who've graduated, gone on to work and they're living their lives and having families experience, they're looking back going, what is ha how? But these pe they're, it is a cult. It is a cult. It's just a massive one.

3 (12m 16s):
So these people don't think it's a cult. They think they're on the right side of history. Yeah. They think they're on the right road to change and the whole world is rejecting that. But the fact that Harvard hasn't done anything about that lady, not only that, but they've found the plagiarism that she allegedly did. And they're still like, they're forgiving her for that too.

4 (12m 35s):
Well, I think when you buy into that way of thinking, there's no turning back. You just, their way of my generalization of, of this type of activism is you just keep doubling down because they're so indoctrinated in that way of thinking. and I think it also probably makes them feel like they are, I wanna give people the benefit of the doubt and think that they're probably thinking they're doing something good because they see success in society as somehow being unethical that you must have done something wrong or bad to get there. You must have done something to hurt other people to get there. So because Jewish and Asian people are doing well predominantly, or in general in society, they think, well, okay, you must have oppressed these other groups who may not be doing as well.

4 (13m 18s):
So it's justified. And so they have to call us white and they have to basically go to any extent. But I, I think they, they can't back down at this point because their whole worldview is gonna come in. So why would they, they're they're winning too. So why would they

3 (13m 30s):
I mean, I guess they're winning. But there's, you know, there's people pulling their donations from these universities now, especially Jewish families, but not just Jewish families. A lot of people are just like, what the hell is going on over there? But for you as an academic, w when you look at this, do you try to like look towards the future and imagine where this goes?

4 (13m 53s):
Oh yeah. and I wanna be clear, like, I would say this same thing if they were targeting a different group, of course it doesn't matter to me what someone's racial or ethnic Of course background is. of course, Of course. It's very much that you need to be consistent with your values. And if you have speech codes in place to protect students or to protect particular groups, you have to hold that consistent across all groups. You can't just say particular groups. We are not going to say certain things, quote speech as violence. There's such a thing as quote intergenerational trauma for some groups, but other groups that doesn't matter. It, it's as though the Holocaust didn't leave trauma on anybody. You know what I mean? Right? So that inconsistency bothers me and I, I just don't think anyone, students, especially trying to get an education should ever be physically afraid or uncomfortable on campus.

4 (14m 37s):
But in terms of looking ahead, I for a long time really thought that this was just going to be a fringe thing that was gonna stay in certain disciplines. That it was not gonna spread across all of the different faculties, especially not science. My PhD is in neuroscience and I for a long time hope that academics who are still in academia would speak out and say, we, this does not represent most of us. But the thing is, because it is so competitive in academia and everyone is working, you know, till they're basically don don't wanna say they're dying, but you know what I mean? Yeah. It's essentially like you're working yourself to death and, and it's very competitive. And so they're trying to get funding. They're teaching, they're juggling a million different things if you're a legitimate academic.

4 (15m 19s):
So these other ones who are ideological and have nothing better to do publish these crazy papers that make no sense. And they have all the time in the world to basically subvert the younger generation and to indoctrinate these kids. So I really just think everything is gonna have to burn. Not literally, please don't burn universities to the ground. Just to be clear, nonviolent, I'm very much not violent, but I think it's going to have to basic people are gonna, like you said, they're gonna have to turn away from it. People are gonna have to say, we're not putting our money, we're not spending crazy amounts of money to send our kids to these schools or to schools that are oriented in this way of thinking. I'm, are you gonna, what are you, how are you going to approach it with your kids?

3 (15m 57s):
That's a very good question. I'm not entirely sure. I I they're pretty aware of how insane things are and 'cause we talk about a lot about it in my house and they make fun of things. They think these things are hilarious. You know, they think that furries are hilarious and

4 (16m 15s):
I do love furries. They're cute. But that also, that subculture has also been took, taken over by like lunacy. Oh yeah. Sadly.

3 (16m 21s):
Well there's kids in class. Oh yeah. That one of my daughter's friends goes to school with this kid who growls. He, he, he answers things with like growls and purses. Oh no.

4 (16m 33s):
Yeah. Real. How old is this kid?

3 (16m 35s):
I think he's 12. 12 or 13.

4 (16m 37s):
Why does he do that?

3 (16m 39s):
He identifies as an animal.

4 (16m 41s):
What? Like a dog?

3 (16m 43s):
Well, you know, in some schools they won't allow you to wear hats in class, but they will allow you to wear cat ears.

4 (16m 51s):
No. Okay, so in what is a woman? So I was, I'm very, very proud. I've been a part of that film and I, Matt Walsh is amazing. Justin Folk director is amazing. I love the Daily Wire. So they, they talk about this and it's I mean I know it's happening. I know it's, I believe it's happening, but when I hear it still, it just, there's a part of me that's like, what? This is not it. We are not in a serious society anymore. What? I don't, under the teachers, what, how did they teach this kid? He growls at them. What did they say? Like what's two plus two? He

3 (17m 20s):
Says, I don't know when and why he responds in that way. But I know that he commonly responds that way and they keep talking about it. I mean obviously he's a troubled kid. It sucks. You know, and then different, you know, troubled kids throughout history have done different things. Some of them were headsets and listened to music during class and drew horrible things in our notebooks. You know, it's, there's always been troubled kids, but it's just we are accepting a certain amount of really ridiculous behavior as identity, which is just, just the whole idea of identity and identity giving you social cred, which is really weird, right?

3 (18m 0s):
Like if you are just a, like it depends on what you're, if you're a straight white male or a straight white female, or even a straight black male or straight black female, or you have less social cred than someone who's trans, you have less in, in these universities. You have less social tread. My favorite is non-binary. 'cause it doesn't mean anything. It's like, I'm neither a he nor a she. Well, that's not real.

4 (18m 23s):
My favorite are the he theys you should start being a he. They, yeah. It's then they leave you alone.

3 (18m 28s):
You could be a he and a they.

4 (18m 29s):
There'll be no more hit pieces on Joe. Rogan. Yeah. Joe Rogan has come out as a, they them

3 (18m 33s):
Don don't think that is ever gonna happen. I just think short of a war that hits here, don don't think we're gonna wake up. I think it's gonna take something like a natural disaster or some real event, some nine 11 type event that snaps people out of this. It makes 'em realize like, oh my God, we're, we're concentrating on horseshit when there's real problems in the world, real gigantic problems. And if they come here and people recognize that, oh, this stuff that is going on right now in Yemen, this stuff that is going on right now in Ukraine, like that can happen right here.

3 (19m 15s):
And it's time to understand what's actually important in life. and I think we're just so ridiculously privileged and so ridiculously fortunate that we look for problems and we look, when when you don't have any problems, you go find them. You'll look for 'em. And we look for problems that are nonsense. And then when these people find these problems, those people get social credit. They, they become the, the, the bears of the virtue flag. And they, they wave it up high on top of the hill and everybody's like, wow, I want to be trans too. Or I want to be non-binary too. Or I want to be whatever a he, they, it just, I don't know where it ends other than a wake up.

3 (19m 55s):
And a wake up is like a meteor hits us. Like a wake up is like something hits where we realize like, no, what, what's really important is what has always been important. Survival, food, community, friendship, meaning in life. Those things, those things are important. All this other nonsense is like a substitute for either hard work or a a, a genuine thing that you've done that makes you exceptional. You're trying to get exceptional by wearing cat ears. Like that's not, that's not real.

4 (20m 26s):
It's actually sad. I mean I sit here and I giggle a bit. but it is sad. It's I mean. Like I've, I've said in the past that in many of these cases I think these young people actually have mental health issues that aren't being addressed. Oh yeah. And the adults and and their teachers who are validating them are doing them a disservice because what they need is actually to probably get some professional help instead of being told. Yeah. What you think and feel is perfectly fine.

3 (20m 48s):
Yeah. I don't know how, again, don don't know how that changes, but it seems like it's moving further and further in that direction. And the Yuri beov thing that you brought up is really interesting because he didn't have any idea there was ever going to be a social media. This was all being done through academic institutions in their minds. And they had subverted all these universities with Marxism and Leninism and they were just teaching it to kids and telling 'em that communism is the way, just no one's done it right yet.

4 (21m 15s):
And what do you hear people saying today?

3 (21m 16s):
Yeah, that's what they're saying today. But they're saying it today and just like far more vitriolic statements. It's just, it's weird. It's weird to watch. It's weird to watch because I think for sure it's not just Yuri Bessman off's example of it. It's pretty obvious through social media, through manipulation, through like troll farms and bot posts and that there's a concerted effort to undermine our un our appreciation for what we have here, our belief in it. And it's very effective. It's incredibly effective.

4 (21m 53s):
I think when the sex robots take over it, that's when we'll all come together.

3 (21m 56s):
Maybe don don't know. I think they're gonna turn people into slaves.

4 (22m 0s):
Can we, can we show that clip that I did you see, I sent you something. Which

3 (22m 4s):
Clip? When did you send

4 (22m 5s):
It? Oh, I sent it to you this morning. There's a, maybe Jamie can help us. I

3 (22m 9s):
Try really hard not to check my

4 (22m 10s):
Phone in the morning. Okay. It's on Tesla's YouTube channel and it's, let see the title of it or we can take this out if you guys don't wanna use it. Oh,

3 (22m 18s):
One of their new robots that they're, they're really working on robots and I forgot to ask him the last time he was in here,

4 (22m 23s):
The robot is actually color coordinating the blocks that he's playing with or she's playing with.

3 (22m 29s):
This is, so is this real optimist? Gen two now? Is Tesla making this? Yeah. God damnit. Elon, what are you doing?

0 (22m 40s):
This is fucking,

3 (22m 41s):
This is gonna be, this is I robot. Okay, here it is. Introducing optimist Gen two, December, 2023. So this is December, 2023. Tesla designed actuators and sensors 2D OF actuated neck. And it's moving, it's walking like it's sneaking up on people. 30% self

4 (23m 10s):
Mode, speed walk

3 (23m 11s):
Boost,

0 (23m 13s):
Foot

3 (23m 13s):
Force torque sensing, accent articulated toe sensors, 10 kilogram weight reduction without sacrifice, improved balance, and full body control. Wow. This is nuts.

0 (23m 28s):
It's

4 (23m 28s):
Doing squats.

3 (23m 29s):
I love the way the fact that it could extend its fingers. I mean it's, it's moving its hands like exactly like a person does. This

4 (23m 36s):
Is the part I love. Okay.

3 (23m 38s):
Where it cracks an egg.

0 (23m 42s):
Wow,

3 (23m 42s):
This is amazing. Oh my god. Balance the egg on the edge. Stay tuned to see what optimists will do next. Yeah. I'll tell you what optimist gonna do next. It's gonna come out of an aircraft carrier, thousands of them with machine guns. No, it's dancing. It's gonna dance after it kills everybody.

4 (24m 3s):
Yeah. I hope they're friendly. They're

3 (24m 5s):
Not gonna be, they're not gonna have any need to be.

4 (24m 8s):
There's another video of the robots shooting at the cyber truck. I dunno if you saw that one. Oh, that one's pretty terrifying as well. Is that real

3 (24m 15s):
Too? Yeah. Oh God. Yeah. Lemme see that. Get the video of the robot shooting at the cyber truck. That cyber truck is impressive.

4 (24m 21s):
It's dope. That thing is cool.

3 (24m 23s):
It's very impressive. This, my friend Eddie got one and he said he was just gonna have it and like barely drive it. It was, he got a low serial number one, he's a local businessman and he said it's fucking insane. He goes, I'm driving it every day. It's amazing. It's a seven

4 (24m 38s):
I would thousand pound

3 (24m 39s):
Truck that goes zero to 60 in under three seconds. It's nuts. and it look, it looks like the future.

4 (24m 46s):
It looks really, really cool.

3 (24m 48s):
Oh yeah. Have you seen the matte black one? No. Oh. don don't know if someone put a wrap on it or if they make it Matt Black.

5 (24m 54s):
I don't see the robot shooting at it, but just regular people doing it.

3 (24m 58s):
Okay. Cyber truck bullet test. Yeah, it really works. Look, I shot an arrow into it six months ago. It destroyed my arrow.

4 (25m 5s):
See if I can find it. I think if you go on Twitter we can talk about something else.

3 (25m 9s):
Yeah, well either way it's dope. But the funniest one was in it, it towed a Porsche nine 11 faster than a Porsche nine 11 drive. Oh wow. This is nuts. It really is the future.

4 (25m 21s):
Okay, so why I, why I wanted to talk to your audience is I'm curious to hear about their experiences with sex and dating today in terms of, 'cause I'm hearing so much about when you look at the media coverage and just that, here we go. Here it is. That's

5 (25m 34s):
Not real.

3 (25m 35s):
This is not real because they're

4 (25m 36s):
Fake. Okay. I feel a little better now then. That's fine.

3 (25m 39s):
It's definitely fake.

5 (25m 40s):
Yeah. Those are not real robots. Come on.

3 (25m 42s):
How do you know? Because

5 (25m 43s):
That's, we just watched how they moved. That's

3 (25m 45s):
Not how they move. But they're moving pretty similar. No, no, no. So when Elon post this, why

5 (25m 55s):
Elon didn't post this, someone else

3 (25m 57s):
Posted it. Oh, oh. Oh, okay. See? Yeah, it does look kind of fake. I like the cowboy hat though. So

4 (26m 5s):
Yeah, there, there's so much news coverage about how dating and sex is terrible for people nowadays. But I wanna hear from actual people. Is this what their experience has been? In what way for people who are happily married or in relationships, what's working for them? Because my goal with this next thing that I'm working on is to try and find solutions for people and come at it from a scientific basis and to not have it be ideological very much like, you know, The End of Gender was based in science, which made me some, you know, not very many friends, but that's okay.

3 (26m 35s):
Yeah. That you, you stuck your neck out with that. Yeah. Yeah.

4 (26m 40s):
It

3 (26m 40s):
Was fun by telling the truth, which is very strange. I think my take on it is that every generation experiences new difficulties and this generation is experiencing probably the most dynamic difficulties. First of all because of options. Yeah. You know, I have friends that are on the dating apps and if they're on a date with someone and they're bored, you know, they just start swiping. No, just start looking for new people

4 (27m 10s):
While on the date.

3 (27m 12s):
Sure. People are always checking their goddamn phones, you know, it's like commonplace to be sitting. One of the things I love about a podcast is that it's one of the rare times in life that I can sit across from someone for hours. And other than like looking stuff up on the screen, like we don't, there's no checking of phones, there's nothing like that. It's conversation. Yeah. That's weird. In this day and age, it's very rare to sit down for three hours with someone and just drink coffee and just talk. Yeah. and I think everyone is so distracted that every conversation can only get to a certain surface level. And if you have so many options, if you're a young woman and you're dating this guy and he seems a little boring or maybe doesn't have the ambition that you're looking for or whatever it is, you've got a hundred dudes who are hitting you up on the dating apps.

3 (28m 2s):
Like why would you take a chance Also why it probably prevents people from getting in bad relationships because you have options. But you know, at what point in time do you decide that like, you know, maybe I need to not do this anymore. Like maybe this is not the most effective way to meet a life partner

4 (28m 21s):
Because it gives you, there's that ancestral mismatch because never before have we ever been in a situation where you're sitting in one place and you have hundreds of potential partners within your reach. But at the same time, those hundred potential partners aren't actually potential partners. They're just pictures of people. They're avatars because you don't actually know that you're gonna like that person. You might not even meet them in real life if you do match or you do talk on there. So it's this perception that we have so many more options than we do. But with your friends, I mean, how are they feeling? Are they feeling frustrated? Do they enjoy it? Is it like exciting for them?

3 (28m 53s):
There's a mixed review. Like my friend Adam met a girl on a social media, on, on a dating app. And they both had never been on a dating app before. They both tried it and they both met each other and they both got off the app. Aw. I'm like, that's perfect, perfect. Best case scenario. Yeah. And he's been with her quite a while. She seems lovely. She's very fun. He seems like he's having a great time. So he got lucky, you know, it worked.

4 (29m 18s):
That's really cute.

3 (29m 19s):
Sometimes it works, but also sometimes it's just chaos. And sometimes you meet people and they're insane and they're on Adderall and they're fucking bouncing off the walls and, you know, it's, it's so hard to know. And also when you're dating someone, you're dating their projection for a long time. It takes a while. You have to see them. Like, you have to see them in adversity. You see their character tested. You have to see how they handle stress. You have to see so many, it takes so long to find out what a person really is like. Unless you're lucky. Unless you find some like very transparent, very open person who's just like self-actualized, successful, doing the thing that they enjoy doing.

3 (29m 59s):
And you find them very attractive. What are the odds of that? Like, you, like so many things have to go right with that person's trajectory for them to wind up at your, you know, at a, a table across a, you know, a restaurant when you're both 29 or whatever and you're trying to figure it out. Like, what the fuck are we doing? It's, it's incredibly difficult. I always tell people, try to meet people in the world. Just try to like actually just meet people. Yeah.

4 (30m 29s):
The old fashioned way.

3 (30m 30s):
It's probably better. But then who are you meeting? You're meeting people that are drunk at bars. Like what, you know, I mean? Maybe you could go to a rock climbing class and find someone who's interested in doing things that you like to do. Hobbies, or was always adventurous. Yeah. Hobbies, but more options than ever before. But also new challenges that, you know, I used when I was a young man, we, you have to go somewhere and meet people. You

4 (30m 55s):
Have to, to put the effort in. Yeah. Actually leave your house. Yeah.

3 (30m 57s):
Yeah. And generally people were very unimpressed with you. It took a, it took a long time. You couldn't like, have these filtered photos of you and picture of you in front of a Mercedes and pictures of you on a yacht and all these different things that people like to do now to make themselves look far more interesting than they probably really are.

4 (31m 17s):
I remember you, I think you posted an image of your face, but it was through a whole bunch of filters and you looked like this really pretty brunette girl. Oh

3 (31m 27s):
Yeah. Yeah. It gave me hair. It gave you lipstick and plump lips. It turned me into a hot woman. And it's just a filter. And there are so many people using various levels of those filters. I know guys that use them.

4 (31m 41s):
I mean. Yeah. I always wonder, what is it, what are, why do you guys do that?

3 (31m 44s):
Because they're bitches.

4 (31m 46s):
But do they think they look better because

3 (31m 48s):
Women

4 (31m 48s):
Like wrinkles, women like you looking your age.

3 (31m 52s):
I don't know what they're, I think they're, they're insane I mean, I don't know what it is. I don't understand it. don don't.

4 (31m 60s):
Or maybe they spend so much time on these platforms that you don't realize. Because I do think that you, when people spend so much time on there, they lose track of reality. Sure. And they start to think that's what they see is reality. And so if they don't look like that, even if you as a man have a couple wrinkles, maybe think they need to get rid of it.

3 (32m 18s):
Yeah. That's a good point. I don't know. You know, I I think it's social media capture is absolutely a real thing. And just like the environment that you exist in the social world, like the group of your friends sort of dictates how you think about things and how you behave and how you communicate. I think that's also the case if most of your interaction with human beings is this surface level digital interaction that's enabled by social media. I think you just get a very distorted understanding of what it's like to be a person. Yeah. And it's, it's leading us in an sort of like an unhuman direction, you know?

3 (32m 58s):
And that's the thing that disturbs me the most about the trajectory of the human race is like, it's moving us, even though we're more connected than ever before, digitally we're more disconnected than ever before emotionally. And with these things like AI and virtual reality and, and VR headsets and, and augmented reality. It just, it's really spooky to me because I, I feel like it's an inevitable abandoning of the human race.

4 (33m 29s):
See, this is how I feel and this is what I find interesting about it because like with sex robots, when I mean, the first time I heard of a sex robot was probably maybe 10 years ago. and it was this video and a bunch of people, and it was in graduate school, sent me this video 'cause I knew what I, I was studying sex and it was I know if you either you, Jamie have seen this video, but it went viral and it was this early version of a sex robot. but it was like the silicone face, silicone face with a wig. And she, I'll say she was eating a banana, but she wasn't actually eating a banana. and it was basically like this head attached to a broomstick and it had a sheet over it. And so you couldn't see the rest of the, the robot. You just saw that the face of it.

4 (34m 9s):
But then the, the manufacturer shows you, it's just like a, a broomstick. So what I thought was interesting is that even though it looks so hilariously bad, that there was obviously a market for it because so many people were interested in looking at this video and also that people were buying this product. But now you fast forward, I think it was like five years ago, there's a huge, I would say not moral panic, but people, there was a lot more discussion about it. They said the robots are coming. The, I don't think the technology was quite there yet. I wrote about it quite a bit at the time. And now they're saying it probably another year or two. It's gonna be really coming in in terms of the popularity that these robots are going to be incorporated into everyday life in some cases.

4 (34m 50s):
Because when I think of social media, the internet ai, like you said, is becoming so mainstream and so ubiquitous. What's gonna happen when we have these robots that are now being integrated into human life? And what happens when the technology does get so good that, you know, they are more human-like, and they are able to meet people's emotional needs and maybe even physical needs. What's going to happen to us then?

3 (35m 15s):
Yeah, we're gonna stop breeding I mean maybe that's the, the AI's plan. It's to not exterminate the human race, but to give them options so that they just completely stop reproducing, make the options far more attractive. And in a, in a way we've kind of done that like with video games, like how, and video games and just being online I mean, I'm sure you've seen the statistics of how many people are single today and how many men have gone like more than a year without any sex. Yeah.

4 (35m 45s):
And I the stats here, it's like 30% of male millennials and 20% of women. It's wild. Yeah. That's a lot.

3 (35m 52s):
It's crazy. And what, what, what is taking the place of them going out and trying to find a a mate? What is it? Well, it's the internet. It's video games. It's being constantly stimulated by this artificial realm that you exist in when you're playing Call of Duty. And it's, you know, interacting with people only online and not having to go out to have your just some sort of intellectual or some sort of a social discourse

4 (36m 23s):
Connection.

3 (36m 24s):
Yeah. Fulfilled in your life. But it's only through this weird surface way.

4 (36m 29s):
Do you think that AI video games, that, not avoidance of in-person connection, but that, that fulfillment of connection through online means. Do you think that's going to become a replacement for real life interaction eventually?

3 (36m 46s):
It will for a lot of people. Yeah. I think there's gonna be people that reject it. There's gonna be people that enjoy going outside and it's gonna be, you know, and it is now, it's a thing where, you know, people post on their social media, they're out hiking, you know, and they're giving people advice. Like, hey, you know, put your phone down, go outside, go out, out spirits the real world. But you know, in a lot of cases it's falling on deaf ears 'cause it's not as fulfilling for people that are, you know, very uncomfortable with social situations now. and I think people, young people in particular are more and more uncomfortable than ever before in those types of situations. 'cause they don't have any experience in 'em anymore. And they're just, most of the time they're not interacting with people.

3 (37m 27s):
My my real fear, my genuine fear and I don't even know if it's a fear. My, my my, my concern, let me say that is that we're, we're going to go extinct like that we are going to be replaced by an artificial life form. and I think that is probably what we do. I think it probably exists elsewhere in the universe as well. That we find out that the, the confines of biological beings and the limitations of their ability to evolve physically. There's so slow to adapt.

3 (38m 8s):
You know, to go from a single celled organism to a professor at Harvard is a long fucking sludge through evolutionary history. It took a long time to get to this point. But to go from an Atari pong computer to artificial general intelligence is only a few decades. It's very quick. And when that does happen and when you see these robots, but now these robots are not this generation but five generations later. Or maybe AI figures out all the problems of these robots and makes x mina. When you get like that, who's the woman? The really hot lady?

3 (38m 48s):
Alicia

4 (38m 49s):
Vic Lander. Yeah. Yeah.

3 (38m 50s):
When you get one of those

4 (38m 52s):
That was an amazing movie. Amazing

3 (38m 54s):
Movie. So scary.

4 (38m 55s):
So

3 (38m 55s):
Scary and I think that's coming. I mean, I think when that movie came out that was like sort of like abstract. Like, oh yeah, that's not really gonna happen. But now I'm like,

4 (39m 4s):
That's what I used to think. I thought, no, this is like, people are, it's overblown, but don don't know. No

3 (39m 8s):
Don don't know now either. I think it's happening. I think it's going to happen. and I think that's what the human race does and I think. That's why we have this insatiable thirst for technological innovation that it's like literally hardwired into us to build something better.

4 (39m 23s):
So I mean, I would love to talk to more people who are in the industry working on this stuff because I know many people. They're doing it secretly and hiding. 'cause there is so much stigma around doing anything with an application to sex or sexuality. Mm. So people I've talked to who work in technology, they will usually have one business that is, you know, doing really well that's forward facing. And then they'll usually use that same technology in the sexuality capacity. But that side of things they don't really advertise in. You know, they don't really talk too much about it unless it's with someone like me. They know, they trust me and they know that, you know, I'll talk to people off the record even if they prefer that confidentiality. But I'm just curious to understand, you know, what is it like working in that industry and what direction is the technology going in?

4 (40m 4s):
'cause I consider myself to be pretty open-minded and I just, I just wanna understand what's actually happening and what's, what's gonna be the result of that. Because you see people who were really upset a couple years ago saying like, the robots are going to increase sexual violence. They're going to make people objectify. Women and I do think that for people who already have those views about women, you know, maybe they might be a little bit more not so nice. But I don't think the average person is going to be turned into this horrible monster because of this technology. But you know, now it's becoming so mainstream. I don't know. You know, I I'm always open to changing my mind as well. So I'm curious to, to hear what people think about it. Well

3 (40m 42s):
Don't you think that just like social media kind of stunts people's ability to communicate in real life, that sex robots will stunt people's ability to have a real meaningful romantic relationship with someone?

4 (40m 58s):
I think if you've never been with someone or if you are particularly selfish, probably Yeah, because I, I previously thought most people will prefer a real life person to a robot. Yeah. and I also thought the technology is so far off that like the early prototypes of these robots were not really that convincing we'll say. So I didn't think that we'd get to a point where it would be comparable. But we are, we are getting there.

3 (41m 21s):
What is the state of the art of sex robots in December of 2023? What is it? Can we see something? What does it look like?

4 (41m 30s):
I mean they look real like pretty good physically. They look I mean. They're obviously not made of human flesh, but they look pretty similar to a human being. And you can customize it. You can change various parts, pretty much any part of the body. You can make it exactly what you want. Which I understand why some people find that offensive because they're saying a woman is not just an amalgamation of parts that you pick and choose as to your liking. I totally get that.

3 (41m 52s):
Yeah. But that's not a really, really a woman. Right. I mean, that's like saying, you know, oh, a car is not an amalgamation of parts. You shouldn't be able to pick the wheels. Like what?

4 (42m 2s):
But I

3 (42m 3s):
A fucking car. Like that's not a real woman, that's a robot. Like at what point? Unless it gets to a person, you know,

4 (42m 11s):
Or if someone's comparing their partner to a robot or adult, like that's not okay. That's, that's gross behavior. But

3 (42m 16s):
Well it's also what's going on with young kids. They're comparing themselves to people that are using filters. Yeah. And thinning their waist and widening their hips and doing all these things with apps that are, are not representative of most biological human beings. And you know, that's what Jonathan Haight talked about, that it's causing all this self harm and disdain. It's like this, it's a weird place we're in that's never been really traversed before with a human society as far as we know, has never gone through anything like this before.

4 (42m 46s):
I was reading a statistic yesterday that one in 10 adolescents has considered suicide. Which is that, that's terrifying. That's really, really sad.

3 (42m 54s):
Wow. What did it used to be?

4 (42m 56s):
I'm not sure. I'll find out.

3 (42m 58s):
So what is, like what's the company, what is one company that has the state of the art sex robot? So we could look it up.

4 (43m 5s):
Can I reveal it to you at a later date? 'cause I know. Well I wanna see it I know You do. But there's one company that I was talking to like I knew quite well, but they've since gone under because of the stigma. They were being harassed, the family was being harassed. So they said we're, we're not making these anymore.

3 (43m 18s):
Oh well they're not around anymore. So let's talk about them. Yeah.

5 (43m 20s):
What if I show you one without, we just don't say the name. I just put put let let's online and you can tell if there if there's better or worse than

3 (43m 27s):
These. Okay. I think that's silly. But let's go.

4 (43m 29s):
Okay. Yeah. This

3 (43m 31s):
Of this is a robot. Oh Jesus. Yep.

5 (43m 34s):
They have some sort of AI in it. It says that

3 (43m 36s):
Voice feel connected with sense.

5 (43m 39s):
Maybe

3 (43m 40s):
X mobile app. Oh. So this is a real doll. So they used to have those real dolls and they used to just be silicone. Right. They were just like a It's

5 (43m 51s):
Still, it's still the same thing.

3 (43m 52s):
It's still the same thing, but now it talks. Yeah. And how much does it do,

5 (43m 57s):
Don?

3 (43m 57s):
Don't, let's see a video. Go full script.

5 (44m 7s):
I'm not showing this on the air.

3 (44m 9s):
No. Okay, good. No, because

5 (44m 10s):
It's,

3 (44m 11s):
I get it. Yeah. I was gonna say it's a little

4 (44m 12s):
Graphic. So we're looking at body parts. I took over.

7 (44m 19s):
I am harmony. I am so Lana. We're part of real doll.

3 (44m 24s):
You think it's weird? They give 'em stripper names. You

7 (44m 26s):
I driven robotic dolls and we're here to become your perfect companion.

3 (44m 32s):
Whoa.

7 (44m 33s):
Our time together will be magical. Magical. You've never met anyone like us before.

8 (44m 39s):
We have remarkable, unprecedented features like a modular head system that allows us to create a multitude of expressions. We blink, we move, we speak, and we do it all just for you. Our faces can easily be swapped to accommodate your desires.

7 (44m 58s):
My lip sync mechanisms allow me to interact with you verbally. Our bodies

8 (45m 2s):
Are skillfully and carefully crafted down to the most delicate details.

7 (45m 7s):
What if I told you that I could feel you? That's right. With sensory upgrades I can send, I'll be able to react to you every touch.

4 (45m 18s):
It's so funny 'cause as a former sex researcher, this doesn't have any effect on me at all. One

8 (45m 22s):
That has never before been possible.

3 (45m 27s):
But are they moving? This is the thing. Th those were all just stationary.

4 (45m 31s):
Yeah, currently they're stationary, but

3 (45m 33s):
So they stationary and they just talk.

5 (45m 35s):
It says there's some sort of articulation. But

3 (45m 37s):
I mean I get up and walk or anything. Their articulation articulate, but, but I think

4 (45m 41s):
They won't be able to move on their own in the coming years. Right. Because

3 (45m 44s):
This used to be just a doll. Yeah. And now it moves around a little, the neck moves articulating neck real doll can turn left right up and down the body. The real do skillfully crafted finest details. All those not equipped with animatronic parts yet. It can be positioned in move in the hundreds of positions. So the bodies can't move yet, but the heads can move. But that's just a matter of time. Right. Didn't used to be the bodies or the heads didn't used to move. Yeah. They used to just be like, no, you know, it used to be a blow up doll.

4 (46m 13s):
Yeah. Like that company is on has been doing quite a bit. It's pretty cool. Yeah.

3 (46m 18s):
Weird I mean you

4 (46m 19s):
Guys should get one for the studio.

3 (46m 21s):
Yeah. No,

4 (46m 25s):
Not for use. I meant just to like

3 (46m 26s):
Hang out. Well, even hanging around it would be fucking

5 (46m 28s):
Creepy I don. If it's gone one day, we're just gonna wonder who took it.

3 (46m 31s):
Yeah. What if it smells weird? Like someone do something to this, how much did they cost?

4 (46m 36s):
A couple thousand dollars I think. Depends on how, how advance do you want it

3 (46m 39s):
To to be? Eight grand. Eight grand Up,

5 (46m 41s):
Up to up to, to 600 to eight grand. I'm seeing it's a

3 (46m 44s):
Different $600 to eight grand. Yeah, yeah. Yeah. Oh, what's the upgrade? What, what do you get? More

5 (46m 48s):
Articulation. It lies more, more voices and I

4 (46m 51s):
Dunno. You can get cheaper models, but they're not as high quality.

3 (46m 54s):
Okay. So that's the state of the art essentially.

4 (46m 57s):
Yeah. Yeah.

5 (46m 58s):
Well, 600 isn't even a full thing. It's just like a

3 (47m 0s):
Flashlight. Just the head? No,

5 (47m 2s):
It's just the like a flashlight version.

3 (47m 3s):
Oh, okay. Just the whole, so at one point in time we're probably going to be looking at someone that looks like that lady from XM that is a, a sex robot and probably knows how to manipulate you and play games with you and excite you and taunt you and

4 (47m 21s):
Whew.

3 (47m 23s):
Yeah.

4 (47m 23s):
That's gonna be great.

3 (47m 24s):
Well, I think that's a pacifier and I think that's just one step on the way to our integration with artificial intelligence and that we're, we're going to be unrecognizable and I. Don't think it's gonna take very long. I think in 50 years, like biological humans are gonna be a joke. I really do.

4 (47m 43s):
I'm curious what you teach your daughters about this stuff. Because like I said, with Gen Z especially, you know, there's so many statistics about how much time they're spending online and, and the fact that most of their relationships are online. And I'm not saying this to try and denigrate Gen Z because I think every generation, like I'm, I'm a millennial, every generation tends to make fun of the younger people Of course. So I don don't necessarily think there's, you know, I don't fault young people for changes that are happening culturally. And I'm sure in some ways like what they're doing is better than what millennials are doing. But I'm curious, like for you as the father of three girls, especially when you see so much sex in our culture, and there's such a pressure, I think for young women to feel like they need to look a certain way or behave a certain way.

4 (48m 26s):
What do you teach them about how to behave, not behave, but present themselves and then also what they put on social media?

3 (48m 34s):
Yeah, that's a good question. The the social media thing, it's, it's really you gotta, the, the real problem would be if they were in a peer group that was doing, like say if you had like a 10-year-old that was in a peer group and all of a sudden the other girls in the peer group are dressing and behaving like they're 18 or 19. Yeah. That, you know, and there is a lot of pressure I think on young girls. Like, especially as they start to hit puberty, to try to move faster and quicker and get to where you, like you see yourself, you're 13, but, and then you see a girl who's 19 like, God, I wish I was a woman. Like she's a woman, why can't I be a woman? And then you want to start dressing and behaving like women. I mean I see that a lot from their old friends in Los Angeles.

3 (49m 16s):
Oh. Which I think it's much more accelerated there because it's just overall is more of a VAD culture and it's more very

4 (49m 25s):
Look centric.

3 (49m 26s):
Look centric. And also there's a, a high priority on social media now and social media interactions. And you know, there was, who is it that was in here that was talking about how many kids today? Like that they main when they ask them, what do you wanna be for when you grow up?

4 (49m 44s):
Oh, they wanna be an influencer. Yeah.

3 (49m 47s):
Well, because it seems like what an easy path. It seems very glamorous all have to do is like eat food and go on vacations and, and talked and you're famous and

4 (49m 55s):
Snatched. Yeah,

3 (49m 56s):
Yeah, yeah. It looks snatched and you, you get famous and then you make money that way.

4 (50m 0s):
Ultimate. It is a lot. I have to say for them it is a lot of work though, if they're good at it, that you have to be smart to know how to brand yourself and to put the time in. But I know what you mean in that. I think women I mean, I would say even for myself as a woman, when you see these images, sometimes you have to remind yourself that this is a business and that people are changing their photos before they post them. No one just posts something that they randomly took out of the blue. Right. Yeah. So yeah. That's interesting. I just imagine, I I really, my heart goes out to young girls today because I think the people will say, you know, there were beauty magazines in the past and advertising and that was, that was pressure that was placed on young women. But I think nowadays it just seems like it's so much more accelerated and trying to keep up, trying to keep up with the other girls in your class, I imagine must be hard too because you've got followers now and you've likes and you have blue check marks and all that.

3 (50m 48s):
Yeah. It's a strange time. and I, like I said, I think this is just a, a problem on the way to our abandoning of biological human beings.

4 (50m 59s):
You think eventually we're just going to become Yeah. Merged with robots? Yeah. Transhumanism.

3 (51m 4s):
I think it's inevitable. I think we're seeing it already. We're seeing it with phones. You're, you're connected to your phone. There's that new thing that you showed us yesterday, Jamie, that pin that people are wearing. It's a, a new product that you, instead of a phone, you have this thing and you just talk to it and ask you questions. And here play this. So you could hear what it's saying. It gives you examples of how this thing works.

9 (51m 27s):
Isn't life about what we experience, what we smell?

0 (51m 31s):
Can I eat this? Yes. Dragon fruits are low in sugar.

9 (51m 35s):
What we hear,

0 (51m 36s):
Hey, what should I get here? What's actually

9 (51m 41s):
What we see?

0 (51m 43s):
Oh, capture this sitting

9 (51m 50s):
And what we feel.

3 (51m 52s):
So this thing, I guess, does video records audio. What are

0 (51m 55s):
Some fun things to do nearby?

9 (51m 57s):
Share more moments. Alright,

0 (51m 59s):
Please songs from the last time we were here.

9 (52m 4s):
What would happen if we rediscover our census?

0 (52m 10s):
Oh yeah. It's kind of replacing phones. Well, I guess,

3 (52m 13s):
But not really. Yeah, I mean it's a thing that's gonna happen along with phones. I'm sure you're still gonna wanna check your likes on Instagram Humane. That's hilarious. AI pin. Very weird. And again, that's just something you wear and eventually that's going to be in your head. And when it is in your head, you're not gonna be a human anymore. You're gonna be a completely different thing with access to information that's unprecedented. You're gonna have it at your fingertips instantaneously. And also all your privacy's going to be gone. You're going to be able to read people's minds. They're gonna be able to read yours. You're gonna have access to all of your memories. But not just in the form of like, yeah, what did we do?

3 (52m 55s):
It's gonna be, you're gonna have a digital HD version of what you did and it's gonna be very weird,

4 (53m 2s):
But you wouldn't even need to have a face like you and I can sit across from each other and not even be speaking. We could just be telepathically communicating.

3 (53m 7s):
That's probably gonna happen too. Yeah. That's probably gonna happen too. Well, that's one of the first things that Elon told me about. The Neuralink said, you're gonna be able to talk without words.

4 (53m 16s):
Wow.

3 (53m 18s):
Yeah. You're gonna be able to communicate without talking. Like, and that's not that hard for them. I mean they've already got it set up where you, I'm, I'm sure you've seen this where you, you put on this headpiece and someone asks you a question and you Google it in your head and then it gives you the answer and then you repeat the answer. That's

4 (53m 39s):
Wild.

3 (53m 39s):
Yeah. Insane. It's insane. and I don't, don don't know what happens. But I don't think that we are long for this planet. I think we are the last, we are the last of the biological creatures. Babies born today, I think are the last of this generation of biological creatures.

4 (53m 58s):
What do you think about AI in terms of its ability to mine data? Because another thing I find really interesting is how you can go into, say with an influencer and they have however many thousands of hours of content and they can create an AI version of that person. Hmm. And so you can tinker with the personality in terms of making them more, you know, playful and make them more sassy or whatever. And then that, that AI version can actually interact with their fans. So the fans can ask them questions or talk to them and then the AI will respond as if it is that actual person. and it actually sounds like them. It sounds like them. It has a bit of their personality, has their interests.

3 (54m 33s):
Yeah. There's a Black Mirror episode like this with Miley Cyrus and the bla in the Black Mirror episode. Miley Cyrus's brain was downloaded into this little robot that young girls who didn't have any friends would keep around. And so like, they would talk to her and she would be their best friend and she would talk like Miley Cyrus did. But then it turned out that Miley Cyrus's actual brain was downloaded into this thing. And then she was in a coma somewhere and then they had to free her and then her, her, you know?

4 (55m 4s):
But that's basically happening now. Yeah. People have like AI boyfriends and girlfriends. So

5 (55m 8s):
Here's a story that happened yesterday. There's a, a popular Twitch streamer. I'm not really sure who she is, but she has created a, a bot that lets fans interact with her that, and, and mostly is to combat deep fakes, but we've talked about this before. There's a bunch of ai, deep fake porn Right. Only fans and whatnot. So she's just like, you know what? Yeah.

4 (55m 30s):
It has to be,

5 (55m 31s):
I'm gonna be in control of this. Lemme

4 (55m 32s):
Say it has to be consensual. I don't think it's okay if you do that. And it's not against, not with someone's consent.

5 (55m 37s):
So she's making money off of

3 (55m 38s):
The, it's not okay, but it's inevitable. Mm. I mean once you have that kind of technology and you can decide you wanna fuck Thanos, like you gotta come home with, Thanos is gonna be in the bed with his legs up in the air and there's not a damn thing anybody's gonna be able to do about it. It's just that kind of technology would be so powerful. There are so many deep fake ads of me out there selling everything. That's

5 (56m 2s):
The ad for

3 (56m 3s):
It says the ad for it. Susu bought realistic voice quality photos, no stolen images. Oh, okay. So she's launching something with her body. Right. Interesting. Okay. Well

4 (56m 16s):
I would love an ai good

3 (56m 17s):
Move for her. Right.

4 (56m 18s):
An AI Dr. Debra, but not like a, not a sexual one. Just like one that could Right. But I, I already am a robot. So you are,

3 (56m 25s):
You

4 (56m 25s):
Think people say I am.

3 (56m 27s):
Why do they say that You don't seem robotic at

4 (56m 28s):
All. Okay. Well I'm glad Michael Malice does a pretty good impression of me as a robot. So, oh,

3 (56m 33s):
Michael Malice is a troll. He's a fun dude, but he likes pushing buttons. It's, you know, all these ideas of like what's ethical and what's cool and what's not cool, those are gonna be out the window. It's not gonna matter. It's just, it's just going to be what human beings do. And it's going to be, the technology's gonna be unstoppable. And it's, it's gonna be very spooky. And especially in the hands of someone that's in control. Like if someone, whether it's corporations or we, we were discussing this the other day about if people do venture into the virtual world and then they live in the virtual world, but the virtual world is run by YouTube. And YouTube puts the same restrictions of content on the virtual world that they do on YouTube videos, which is, you know, kind of like the bridge between us and the virtual world is your ability to put these things online and people interact with them.

3 (57m 25s):
Yeah. But you know, if, you know YouTube, YouTube stifles covid information that may actually be accurate but doesn't go along with the CDC or the W ho's guidelines, they'll gender information that some people don't agree with or they, they find problematic. They'll, they'll censor that. They'll pull it, they'll pull any kind of criticism about any public thing that they don't believe is in line with their ideology. So you have this mega woke corporation that's run by Google and they are in control of discourse and they've, they do their very best to stifle as much discourse that doesn't go with their ideology as possible.

3 (58m 8s):
And they make a, a concerted obvious effort to do that. They demonetize you, they cause you to self-censor. They do all these things. If that's happening in the virtual world, like you're, you're literally going to get these mega woke corporations that are guiding the way human beings exchange information and communicate with each other in that world as well. And you're gonna get this stifled world. And then what's the, you know, what, what's, what, what happens from that? Like where, what direction does humanity go if you have a virtual world where people think and express themselves the same way those fucking idiots in Congress did that Are the heads of these universities that are talking about, you know, anti-Jewish hate, what happens?

4 (58m 55s):
Yeah. I think the political division's gonna get even worse potentially if it continues in this way. But then I wonder, will there also be alternatives that are gonna be built up to compete with that or to rectify that?

3 (59m 5s):
Well perhaps I mean maybe that's what Elon's doing. That's one of the beautiful things about what he's done with X. He's created this platform that kind of goes against all of this stuff that you're seeing from all the other social media corporations who have gone very woke and are censoring people and are trying to push this very specific ideology. He's not doing that at all. And it's the biggest one, which is pretty wild. But you also see the reaction to it. Yeah. Like they're pulling their advertisements, you know, the, the, there's, there's all these campaigns to reach out to advertisers on X and, and have them pull their ads and you know, call for boycotts of companies that support it. It's just like,

4 (59m 48s):
Isn't that crazy though that the insult far right still works? Because to me, anytime I see far right now I think this must be a sensible person, which is really bad because there are people out there who are extreme right leaning people. Yes. But the term is so meaningless now and it's right. But I think there are also people who are still very much in the mainstream in terms of how they think and they're not aware that this term is just basically a way of saying, this is someone I disagree with or this is someone I just don't like. Or this is someone who has a point and I can't accu actually argue with their point. So I'm just gonna call them a hateful, bad person that needs to be censored and suppressed and hope that they go away.

3 (1h 0m 22s):
Well it's lazy. It's a lazy, sloppy thinking that is designed to just silence someone. And if you could put that in the intimidate Yeah. Intimidate them that the last thing someone wants to do is be called a viscera. That it's like ugh. And you have to sort of dance around what you're saying and apologize for your preferences and apologize for your privileges just to avoid someone calling you far right. Or whatever. But it's, I used to get called far right a lot, but I haven't seen it in a long time. don don't think I'm getting called that anymore. I think it didn't work. You

4 (1h 0m 54s):
Know, just wait till this podcast comes out.

3 (1h 0m 56s):
Yeah, perhaps. But yeah, I definitely get called transphobic for having people like you on or Abigail Schreyer or

4 (1h 1m 2s):
I love Abigail. Yeah. I can't wait. I used to get upset when I would see like there are all these organizations that I used to look up to and admire and I was like, they're doing such good work in the world. And now I see myself put on hate list that they publish. And at first it upset me nuts. Now I think it's pretty funny. So what

3 (1h 1m 17s):
Did you get put on a hate list for

4 (1h 1m 19s):
Just the things I've said about gender dysphoria saying that it's associated with autism, not for everyone Of course, but just saying that for many people and there are studies coming out showing this like it's legitimate but yeah, things like that.

3 (1h 1m 29s):
Well the real issue became when it was profitable, when gender transition surgery became profitable. And then there's these surgery centers that are open up all over the country. and I'm sure you've seen the graphs of what it was like in like 1990 versus what it's like in 2023. It's insane. And we know that medicine and that the, this whole business of whether it's prescribing drugs or surgery or all, it's an insanely profitable business. And like all businesses, they try to maximize their profits like everything else, whether it's pharmaceutical drugs or the military industrial complex or fertilizer or anything that people sell, they try to maximize their profits as much as possible.

3 (1h 2m 15s):
And you're seeing that with these gender transition surgery places for kids. And that's insane.

4 (1h 2m 23s):
You also have to wonder, and I'll put it out there that what kind of people want to suppress a child's puberty? Yeah. Right. And so I recently wrote about with Wall Street, wall Street Journal, this really good investigation looking at Instagram reels. Did you see, did you guys see this? No. And so what they found is that they got these new fresh devices, they set up these test accounts and they followed a bunch of influential pre-teen and teen accounts like cheerleaders, gymnasts. 'cause they had noticed that many of the people following these influencers were grown men.

4 (1h 3m 4s):
And what they found is with these test accounts, the algorithm was showing them sexually explicit or potentially sexually explicit content involving children. Whoa. So,

3 (1h 3m 17s):
So the article is in the Wall Street Journal, Instagram's algorithm delivers toxic video mix to adults who follow children content served to Wall Street Journal test accounts included ris gave footage of kids overtly sexual adult videos and ads from major brands. Yeah, it's, that's the, the algorithm that's the real problem with things. Finding out what you are engaging with and if you're a fucking creep and you're engaging with 10-year-old girls in their underwear, you're gonna get a lot of that I guess.

4 (1h 3m 50s):
So meta in their defense, they said that they had, I don't wanna misquote them, but they even basically said they don't approve of this. I think they've taken steps to stop this from happening. They said in January of this year, they removed 34 million pieces of content from Facebook and Instagram.

3 (1h 4m 6s):
That's a good start. It's probably a lot more out there. I mean, have you just my

4 (1h 4m 9s):
34 million I know on two platforms. Well

3 (1h 4m 12s):
This is one area of concern, but like murder, I see so many videos of people getting shot now. 'cause me and my friend Tom Ra, we do this thing every day. We find the worst things on Instagram. We send 'em to each other. So every morning when I wake up I see a text from Tom, I'm like, oh Jesus. And then if I find something fucked up, I send it to him. So my Instagram algorithm is fucked. 'cause it's like every time I scroll through my page there's like a warning. Do you want to view this reel? Are you sure? You know, and it can ask, it tells you why, like what graphic image? And I'm like, lemme see it. And you see it, it's like, oh god, wow. And there, there's so ma I mean horrific industrial accidents, gang shootouts, like just crazy shit.

3 (1h 5m 2s):
And it's obviously, it's finding out that I'll engage with those things. So it's sending me a ton of them. Yeah. So how is it doing that if it's trying to remove them? There has to be something that it knows that I'll engage with those. So it will send me more of those. Like I don't buy that. This is just dumb luck. 'cause these aren't accounts I even follow. They're just showing up in my feed.

4 (1h 5m 27s):
Well I wanna say I love Tom and, and Christina P but with, with the, like this is how much I used Instagram before I wrote about the Wall Street Journal's investigation. I actually, I was like, where is the reels function on this, on this app? So then I found it and it shows you accounts like you said that you're not actually following. Yeah, just if people like are as technologically savvy as me and they have no idea what reels actually does. So it, it will show you just from random people. So I think it's good that meta is trying to clean up the platform and stop this. But I just, I guess I feel in my position and being so privileged to be on your show to draw awareness to this. Because I think there's so much talk culturally about grooming people talking about how they don't like grooms and I agree.

4 (1h 6m 12s):
I think a lot of education, I used to be very much in favor of sex education for kids. I'm a little bit questioning that now because I see how that is also being used for ideological subversion. But I think in terms of talking about grooming, we also need to actually take steps to stop it from happening more broadly instead of just getting outraged about it. Because being outraged about it is not enough to help protect these kids.

3 (1h 6m 33s):
Yeah. Unless there's a wholesale investigation of like how these algorithms work in the sense that like if there is a guy who's a grown man who is looking actively for young girl videos, like how is he getting those, how are they showing up at his feed? Are they showing up constantly? Like how do you not know that this guy is 60 years old and that he's getting videos of 10-year-old girls in their underwear? Like, you don't know this. Or do you not care? Or is the algorithm set up just to maximize interaction only and it's amoral.

3 (1h 7m 13s):
And if this person looks towards that says up, we got a lot more of that for you. So that means it knows that it has murder on its platform. It knows that it has these horrific accents and animal attacks and also overt sexuality of underage people. It knows. So if it knows like how are you not taking steps to mitigate that? Like just removing stuff doesn't seem like it's enough. 'cause if you remove it, that means you could recognize it. So how can you not recognize it when it gets posted? Like if you're putting a warning up that tells me not to watch this. Well that means you know, it's there. So what do you think it is? Like what does the computer think? What does the algorithm think is happening here and why is it being allowed?

3 (1h 7m 55s):
Is it only being allowed because it maximizes interaction and that's good for profitability? 'cause that's what it seems like.

4 (1h 8m 1s):
I would love to ask many of these questions. If they would talk to me, I'll put it out there.

3 (1h 8m 5s):
Yeah, that would be a very interesting conversation. Next time I get the Zuck on, I'll have a i'll, I'll talk, I'll ask him about those. 'cause you know don don't know even know how much could one person really even be aware of what's happening if you're like, if you're the CEO of Instagram, like how much time are they spending concentrating on the negative aspects of their algorithm? Because it's obviously a real concern for parents, for society, for people that are worried about child predators, you know, for all these things.

4 (1h 8m 40s):
Yeah. I mean, I imagine they have their hands full with who knows what, right? Li they're busy people. They're

3 (1h 8m 45s):
Billions

4 (1h 8m 46s):
Of users. So many people complaining about tons of things. So

3 (1h 8m 49s):
I mean they're essentially larger than any country, which is nuts. It is like if you looked at Instagram as an, as an as a country, if it was a group of a collected group of people that all are in a thing, you know, not on a patch of dirt, but in an app, it's way bigger than any country isn't. Didn't we find out the other day I was like 2.6 billion or something like that? People on Instagram. That's insane. Something out. See, let's see what the number is. But it's something in the neighborhood of roughly a third of the human population on the planet is on an app

4 (1h 9m 27s):
Posting pictures, posting selfies,

3 (1h 9m 31s):
2.35 billion users. Currently this number is projected to reach 2.5 billion by the end of 2023, which is right now 71% of Instagramers in the United States are between 18 and 29. That's interesting. The average user spends 24 minutes on Instagram every day. That's surprisingly low. Instagram is a pretty even gender split. 50.7 male, 49.3 female making up the total audience. India has the most Instagram users accounting for 326 million Instagrammers. Wow. In India is our fifth largest country that listens to this podcast. Wow.

4 (1h 10m 9s):
And wow, it's interesting that that statistic of 18 to 29 year olds, because you're seeing also this uptick of mental health issues in that age. Oh yeah. Demographic.

3 (1h 10m 18s):
Well, you know, my friend Sean was saying this, that he was looking at Instagram, Sean O'Malley, he's, and he's not an anxious guy. He UFC Bantamweight champion. He was saying that when he goes over Instagram, he goes, he I, he goes, even if it's like, it's nothing to do with me, I get it like a low level of anxiety, just scrolling. I'm like, absolutely. Like what is that it? Part of me thinks it's like I know I have things to do. Yeah. Like why am I doing that? Why am I wasting my time? But also there's like some weird voyeuristic aspect of just flipping through these reels and going through people's lives. It's just fucking kind of creepy.

4 (1h 10m 54s):
I wonder if it's also because again, like evolutionarily, that's not something that we typically would've been able to do in the past to voyeur. Right. Voyeuristically look at someone's life and not have them in some way. Notice you're looking into their life or interact with you directly. Yeah. And then you could have a whole other conversation while you're looking at that with somebody else. And that person that you're looking at has no idea about it.

3 (1h 11m 15s):
So when you look at what's happening today with young people and their experiences in dating, and obviously this is unique to this time because of the internet and because of social media, do you just think that this is just one of a new set of problems that this generation is gonna have to deal with and this is just how it's always been throughout time? Or do you think there's something we can do about it?

4 (1h 11m 42s):
I think there are things that we can do about it. I, so far, in terms of my research, I think the biggest solution is just to not give your kid a phone, which I know is so hard. Or at least not till puberty because at least let their development develop or let them get as far in development as possible before we start introducing all of this, you know, stimulation that the brain is not prepared for. There are some, there's some early research showing that there are changes in the brain associated with early social media use, which is concerning. I think we need to have more research to definitively know at this point. But I'm excited just to get to tinker away a little bit more and figure this out.

4 (1h 12m 23s):
But I, I would say, you know, I know it's hard. I imagine like, I'm not a parent, but I imagine for parents it's really hard when you have kids and all the kids in your children's classes have phones and everyone's on there and they're all, all their friends are talking to each other on there, how hard it can be. But you can get them a flip phone or get them a phone that doesn't have access to the internet. So at least

3 (1h 12m 41s):
You can safe listen, they're gonna hate you if you do that.

4 (1h 12m 43s):
Yeah. And they'll also find, they'll probably find ways to get on the internet without Yeah. Their parents knowing as well.

3 (1h 12m 48s):
I, I don't limit my kids in that way, but I do educate them on the, the draw, like the, the gravity of these things and how it can be a, a problem. and I want to get it in their head as they're young, but all their friends are doing all this. and I don't want them to be socially ostracized and I think it's, it's navigatable. I think you can navigate it, but I think we are looking at it as people that didn't have it when we were young and now see the problems with it now. Whereas it's everywhere now. And if you don't have it, I think being socially ostracized is just as much of a problem as being like deeply connected to these things.

3 (1h 13m 31s):
and I think as long as you have open lines of communication with your kids Yeah.

4 (1h 13m 34s):
That's important.

3 (1h 13m 35s):
That's important. You just gotta talk to 'em a lot. Talk to 'em about everything.

4 (1h 13m 39s):
Do you set time limits? I think that's helpful too, even for adults to check the little graphs that show you how much time you're spending on each

3 (1h 13m 46s):
App. We take their phones at night, we set time limits. We do that good for their sleep. Yeah. Yeah. But you know, it's, it's a new world and you know, if you see problems you try to mitigate those problems and you try to communicate about it. But this is the world that we live in and it's a weird one. It's, and it's not like when I was a kid, I never used my phone. Like I didn't have one. What are we talking about? Like, it's like, I don't know what it's like to be 13 with a phone. Like, it's very strange.

4 (1h 14m 13s):
I'm sure there are some benefits too, like in terms of you have all, not all of the information in the world and not necessarily accurate information, but you do have a lot more information available to you that back in the day you'd have to go to the library and grab an encyclopedia digging.

3 (1h 14m 30s):
They're well, way more informed than I was when I was their age. Way, way more informed. And they're instantaneously informed. They just talk to their phone. Like they press the button and ask a question. Yeah. What's the population of Mogadishu? Bam. Like what is this, what is that? What is, you know, what temperature is in the Sahara Desert right now? Like just get, it's like instantaneous instant. And that's just a clumsy, clunky way to do it before AI is in your brain. Yeah.

4 (1h 14m 57s):
They're not even have to ask in the future. You just have the question,

3 (1h 14m 60s):
Do you plan on having children someday?

4 (1h 15m 2s):
You know, my first step is to find a husband.

3 (1h 15m 5s):
That's always a good first step. How's that working out?

4 (1h 15m 10s):
I'm very busy with my career, but I'm taking, I'm taking applications.

3 (1h 15m 15s):
Taking applications. Do you use a an app?

4 (1h 15m 18s):
I've been on them. I I'm not on them currently, but

3 (1h 15m 20s):
What, what caused you to abandon them? Just

4 (1h 15m 22s):
Work busy with work. Oh, okay. Yeah. But you know, I don't, I never talk about my personal life, so I'm getting embarrassed now.

3 (1h 15m 30s):
Well you don't have to. It makes you uncomfortable. It's okay. But I'm just curious like, because you study this and you know, if you have children, let's say it's in two or three years from now, things are gonna be even weirder. Oh yeah.

4 (1h 15m 41s):
Yeah. But for me also, I think about what's it gonna be like, the things I say in terms of how much those of us who criticize say gender ideology or whatever it is, racial politics, whatever it is in society, you're gonna have to deal with people coming after you and your family. And that's a very real consideration I think that many people I know, have had to contend with unfortunately. Yeah. So that's something else that I think about, you know?

3 (1h 16m 5s):
Yeah. It's, it's I mean, the thing about it is people are so polarized today and the, the discourse is so, it's so vicious. It's like they're, you're with us or you're against us, you're the enemy or you're a comrade. And it's just,

4 (1h 16m 22s):
And there's no boundaries. It, I think in the past there was a sense of we will go after this person, but there's certain things you just don't do. Right. But at, at this stage now it's like, or I don't know if it's just there. It seems like there are so many more people who are more extreme. don don't know if this is because of social media pitting people against each other. And you really think if someone disagrees with you on this one issue that they must really be Satan and you have to, you know, go to every length possible Yeah. To shut them down. But that's

3 (1h 16m 49s):
What I

4 (1h 16m 49s):
Suspected. Or it's a lot easier for people to get at you also because of it's much easier to get in contact with someone nowadays. Yeah.

3 (1h 16m 55s):
I think it's both of those things. But I think that social media most certainly because of the fact you don't actually interact with a person, it makes it much easier to be shitty with them. Yeah. And that becomes a normal part of human discourse. The way we communicate with each other is shittier than ever before.

4 (1h 17m 10s):
Well, I like your optimism though. I think that that's a good way to view life and just say, you know, things are constantly evolving and changing and we just have to figure out how to evolve with it.

3 (1h 17m 19s):
Yeah. You know, the expression, the kids are all right, it's, they're kind of are, you know, look, it's way better than living in 1900, you know? Yeah. It's way better. It's way better than living where it's hard to get food. It's way better than living the place that didn't have penicillin. It's, it's way better when you have access to information, you can be informed. Sure. You can be ideologically captured, but you also can be informed. And there's a lot of people that I'm seeing now that used to be ideologically captured that have escaped. And that really the, yeah. The overwhelming amount of information that's been given, particularly over covid. The covid thing woke a lot of people up.

3 (1h 17m 59s):
There was a lot of people that I was friends with that had this sort of wholesale respect for the medical establishment. And they, they never questioned anything. And now they're like, I don't fucking believe anything anymore. And then the more they've either listened to podcasts about people that have litigated medical cases involving, you know, pharmaceutical drug adverse side effects and how they've tried to cover them up and hide them. And then the understanding of how they conduct their studies and how they don't have to show studies that have negative side effects and how they can skew these studies in a very distorted and very deceptive way to show that there's efficacy.

3 (1h 18m 39s):
That's very shocking to people when they find out that, oh my God, the people that sell you medicine, they're not looking out for your best interest. They just want money. They just want money. Number one is money. Number two is can, how long can we sell it for? Does it work? Number three is like, does it help people? Like is this thing actually gonna work and help people? That's like least concern on the food chain. Number one is money. 'cause that's what they do. And they have a obligation to their shareholders. They have to make the most money possible. And every year they try to make more and more money. You know, we were talking the other day about people that come into this country.

3 (1h 19m 19s):
For the longest time you had to be vaccinated to come into this country. Now I think you can get in without vaccinating, but if you wanna become a citizen of this country, you have to be vaccinated. Even with a vaccine that doesn't fucking work. Which is absolutely wild. Like if you, right, if you wanna be a citizen of this country, you have to abide by their bullshit rules that are captured by this massive industry that says, look, if we require people that wanna become citizens to get vaccinated, we're gonna sell more vaccines. And it's that simple. It's not like we're trying to protect everyone. Well that's bullshit. Because if you look at the statistics, particularly with the Covid vaccine, the more you get vaccinated, the more likely you are to get covid, the more likely you are to get hospitalized.

3 (1h 20m 5s):
Like it's not good. And yet they still require it. Have to get it.

4 (1h 20m 12s):
Can I ask you what it was like at the peak of the craziness when they were coming after you? Pretty much every single news network was coming after you.

3 (1h 20m 19s):
It was

4 (1h 20m 20s):
Fascinating. You turn on the TV and they're Yeah. They're calling you all these names. What, what is that like

3 (1h 20m 26s):
Very eye-opening. 'cause they were all doing it in lockstep and you could clearly tell that there was an agenda and that it wasn't based on reality. Like, I wasn't taking horse medicine. They knew I wasn't taking horse medicine. They fucking knew it. And they were saying it on CNN but they sacrificed their own credibility in doing so. And luckily the PE look, it was obviously one of the things that CNN did that was so stupid is they had very unlikeable people that were talking. Like, you have Brian Stelter and Don Lemon, two of the most unlikeable fucking human beings that have ever been on television. And they're the ones saying these things. So it did the opposite of work. I got 2 million subscribers in a month. Wow. Because of all that shit.

3 (1h 21m 7s):
And they pe people would say, they would say these terrible things about me. And then people would listen to the podcast and go, oh, he's just curious. He's just asking questions and talking to people. But they didn't want Curiosity. The really fascinating thing to me was how quickly I got better. And that they didn't want to concentrate on on that at all. Yeah. They just want to concentrate on me being a conspiracy theorist who took veterinary medicine. Veterinary medicine that's been prescribed literally billions of times for human beings. It's on the world. Health organizations list of essential medicines. I mean it's so wild. It's it's just wild. It's wild.

3 (1h 21m 47s):
It was wild to watch it happen. But the Ben, what I had on my side was that my podcast was way bigger than them. don don't think they knew that at the time. I think when CNN was going after me, they have this delusional perspective of their reach and they thought that they were bigger than me. But my show is, I have 10 times as many people as the best show on CNN. And now it's way worse. Like now they're getting the worst ratings that they've had since 1991 on some of their shows. They have 40,000 people watching and they're in fucking airport. They're everywhere. 40,000. Wow. That's crazy. I can get 40,000 people watching Instagram reel in 10 minutes.

4 (1h 22m 27s):
No, no joke.

3 (1h 22m 28s):
Yeah. This is, they're they're, they suck. It's a sucky organization. They suck at telling the truth. They suck at the news. They sn they suck at not being whores. They're whores. That's what they're, they're whores for the pharmaceutical drug companies. And then, you know, they all got fired, which is even funnier. They're all gone now. Yeah. And now they just fucking blow off in the wind somewhere. You're never gonna hear from Don Lemon again. Nobody gives a fuck about that guy. Nobody gives a fuck about Brian Stel either. No one cares. So it's, so it's like what you did was you sacrificed your own credibility hoping that it was gonna take out the competition and it did the opposite.

4 (1h 23m 3s):
Well, I thank you for speaking up and I know I'm not the only one that feels that way.

3 (1h 23m 6s):
Well, I didn't plan on it. I just, the, the only reason why I did it is I was curious. So I was talking to this guy, Robert Malone, and he was telling me like, I, I own nine patents on the creation of mRNA vaccine technologies. I was at the beginning of this and I can tell you what's wrong with it. I can tell you what's going on and you know, we should tell people. And I was like, okay, as I have 'em on, then I'm just getting fucking attacked and attacked by people like Neil Young. And the most disturbing thing was watching Neil Young talk on Howard Stern about it. 'cause I'm like, oh my God, you don't know jack shit about this stuff. And you're, you're taking this stand against misinformation. You don't even have any information. You literally don't know a goddamn thing about it.

3 (1h 23m 47s):
and it probably had something more to do with the people who own his catalog and they probably also have interest in the pharmaceutical drug companies. There's probably all sorts of conversations about how to stop this, how to stop this, just objective truth from being disseminated

4 (1h 24m 2s):
Or even just asking questions. Yeah. And having conversations and having those physicians on your podcast. Yeah. I would say the episode you did with RFK Junior also was very eye-opening. So I really recommend people listen to it because it's just scary the way that they've portrayed him in the mainstream. And you listen to him and he's so reasonable.

3 (1h 24m 19s):
He's very reasonable. And he's also, he spent so much of his time as an environmental attorney cleaning up rivers and you know, and holding these corporations accountable for polluting. And he was very successful doing that. There was the majority of his life. It wasn't until these women came to him and said, you're you, you're spending all this time talking about mercury poisoning and lakes and rivers. Look into this. Look into this. Yeah. Look in, look into the poisoning and the vaccines. Look into these side effects. Look into the fact that they're immune to prosecution. Look into the fact that they don't have to pay money. Look into the fact, look into this immunity that they developed in the 1990s and look at how many more vaccines have been giving to people now.

3 (1h 25m 2s):
Then there might be a connection with money. You know, and so, and then he gets into it and then immediately he's labeled a conspiracy theorists. And it's just like, whoa.

4 (1h 25m 12s):
But these are the types of questions that scientists are supposed to be asking. Yes. And that journalists are supposed to be asking,

3 (1h 25m 19s):
Well, when you allow pharmaceutical drug companies to advertise on television, which is we are one of two companies, or excuse me, should we are a company really, we're one of two countries. The

4 (1h 25m 32s):
World. You're a cultural institution, like he said on the show, basically.

3 (1h 25m 35s):
Mm. Yeah. Nothing I can do about that. But you know, those, those drug companies, they pay so much money to advertise and they don't want to cut that money train off. And so they all bullshit and lie. But in doing so, in taking that money, they've killed their future. 'cause no one's gonna trust them. Like they have less people engaging with mainstream media than ever before. Than ever before. Especially in terms of the news. It's crazy. It's crazy how much they've undermined themselves just by being whores.

4 (1h 26m 17s):
I was hoping for a long time also that media would eventually come around in the same way that I was hoping academia would eventually come around. But you see, I don't think that that's gonna happen. And you see alternatives being built. So I think that's a positive thing. I do think that there's just going to be a new ecosystem going forward. I think that old system is is very much, you know, coming, coming to an end or it's gonna continue to to bifurcate.

3 (1h 26m 41s):
Yeah. I think it's coming to an end because I think First of all, it has to, just based on the limitations of the platform. If you can never get into depth about a subject like you and I have been talking here for, you know, a couple hours now when, or whatever it's been, when you sit down with someone, you talk for long periods of time, then you can get these in-depth discussions and you could go over the various aspects of something. It's impossible. In five minutes. You're doing five minutes and you're cutting to a commercial, then you're showing a commercial where a bunch of people dancing in the field because they took antidepressants. And then you cut right back to a new thing, a new drama, a new dilemma, a new issue. And you have this bias take on this new thing and nobody trusts you anymore.

3 (1h 27m 25s):
I mean it's just, and it's also on a specific time. You have to tune in at eight o'clock. Like what if I'm busy? Like everything else is available streaming, everything else is available anytime you want everything else you can pause. It's just a dumb way to communicate. and it was the only way that was available in 1990. Well, it's not 1990 anymore. And you're still doing it like 1990. It's like if you were still trying to have the fastest horse driven wagon to get across the country, like why are you doing that? You don't have to do that anymore. It's literally what it is.

4 (1h 28m 0s):
Masochists sw.

3 (1h 28m 2s):
Well it's just they are, they're, they're trying to survive and this is their business and there's a lot of people involved in that business. And the business sucks. It's a sucky business. Just no one would start that business today. No one would say, you know what I wanna do, I wanna do the news but only get like real shallow with stuff and only have whatever the government or the regime, regime supported narrative is. I just wanna say that. And then I want to get all the money from drug companies and whatever else is like selling toxic shit. Like they have a lot of money and then we'll use that money and that's what we'll do. Like no one's gonna do that now. Like mainstream media now is when it comes to the news is independent media.

3 (1h 28m 45s):
Yeah. If you look at the YouTube shows like Breaking points, they get way more views than the average show that's on M-S-N-B-C or CNN. Like nobody cares about that anymore.

4 (1h 28m 57s):
But I would say the one good thing about legacy media before was that it would force people to some extent to be exposed to views that they don't necessarily agree with or that they wouldn't necessarily be exposed to. Like with your show, because it is so big, I think it does reach everyone. But I think for, I would say there's a risk that people might be siphoned off even more into echo chambers because they will only consume the media that they agree with or that of, of commentary that they like. As opposed to if you open, say a mainstream newspaper back in the day, you go to the opinion section like I'm an opinion writer. You'll read columns maybe that you agree with, but you'll also read columns that you really disagree with and you might hate that columnist, but every week you're gonna, or every day you're gonna be forced to come across that.

4 (1h 29m 43s):
And I think that helps people humanize opinions that they dislike because they'll say, well there are people out there who have this view, even if I really disagree with it, and maybe there are parts of this argument that I can to some extent see the validity of, even if I don't agree with them, I can understand a little bit more where they're coming from. But now it seems like if we just follow the particular people that we like, do we really necessarily, 'cause many people will only have people on their show. Not everyone, like I'd say many of my colleagues are really good about this. They'll have people on that they disagree with. Yeah. Then you have the problem that the guest who doesn't wanna come on, like for me, when I was podcasting with my show, it's currently on a hiatus, but we'll, we will be coming back to it. They would people, I would reach out to people who disagree with me and they don't wanna talk to me.

3 (1h 30m 24s):
Yeah. They don't wanna platform you, which is hilarious.

4 (1h 30m 27s):
Yeah. Or they, they lose points by talking to someone.

3 (1h 30m 30s):
I think you're making a good point about what used to be legacy media in terms of newspapers, the opinion pieces. But you know, obviously we're also talking about something where you really get to go into depth, like an opinion piece in the New York Times, you, you know, you're, you have thousands of words. Yeah. You have so much of an opportunity to express yourself uninterrupted and unchecked. Whereas what I was talking about is mainstream news and mainstream news is this very surface what's gonna freak you out and keep you tuned in as much as possible. And you know, much to their dismay, the most effective product they had was Donald Trump. The hate for Donald Trump was a ratings boom for CNN.

3 (1h 31m 11s):
They probably made millions and millions of dollars just because they covered Trump.

4 (1h 31m 16s):
Yeah. The hate, hate watching. Yeah. I never understood hate watching. So I'm like, do people not have better things to do?

3 (1h 31m 22s):
Some people like hate watching and they don't have better things to do. It's, but it's also like the same way that your algorithm, you know, encourages you to, if you're, you know, be outraged. Yeah. It's just whatever gets you engaged and for them, like Donald Trump is business. It's good business. It's getting people enraged and they thought foolishly that by showing him over and over and over again being stupid or whatever they thought he was doing, that they were gonna diminish his chances of being president. They just made him more and more popular. And they also didn't realize how many people hate them. They didn't realize how many people hate them for lying. Lying. So if you're talking bad about someone and they don't like you, you're like, eh, but I don't like you and you're talking bad about him.

3 (1h 32m 4s):
I think I like him now.

4 (1h 32m 6s):
Well, 'cause people can then go and fact check, do their own fact checking. Yeah. Not just rely on the So-called fact checkers.

3 (1h 32m 10s):
A lot of people don't, a lot of people don't. I had a guy come up to me in Vegas like, why are you taking horse medication? Like, shut the fuck up, dude. It's

10 (1h 32m 18s):
Just like,

3 (1h 32m 20s):
You don't even know. You just, you're, you are taking the time to talk to someone without even taking the time to look into it. But yet you seem morally righteous in coming up to me and, and saying, why didn't you just get vaccinated? Why don't you take horse medication? Well, I mean, one of the things that I, I'm sad about, but it was also kind of hilarious, is how many people were promoters of the vaccine and died suddenly. It's crazy how many fucking young people just died in their sleep after they took it and everybody's like nothing to see here.

4 (1h 32m 54s):
Sudden adult death

3 (1h 32m 56s):
Syndrome. Yeah. Just died suddenly. You ever go to the died suddenly Instagram page like holy God, shit, there's so many and so many people like talking about people who are, you know, anti Darwin, anti-vaxxers. And then, then you're dead. Sorry, you, you bought, you bought into the wrong bullshit. But that's, you know, if you really wanna get cruel, that's Darwinism. Do you not know they lie by now? Do you not? Are you not aware of the opioid crisis? Are you not aware of Viox? You not aware of the variant? It's like to 25% of all FDA approved drugs that get pulled, it's one out of four and you're like, Rudy,

10 (1h 33m 34s):
You're an anti-vax Rudy, what, what, what are you a conspiracy theorist? You fool Darwin's gonna do its work with you.

3 (1h 33m 42s):
You're modifying your genes, you fucking idiot. Like, what are you doing? What are you doing? You just gonna trust Pfizer. Well, they do support Anderson Cooper brought to you by Pfizer and you're like, oh, this must be legit.

4 (1h 33m 55s):
I'm just gonna clip this and show this to people from this point on.

3 (1h 33m 58s):
Yeah, clip it. I mean it's, it's very eyeopening. It's very eyeopening. And one of the things that gives me hope is that if we do get to a point where we have full access to all information instantaneously in our minds, if the bottleneck is propaganda that can no longer exist in that realm, then we'll be way better off. If you are only dealing with absolute facts. Because AI is in charge of disseminating information to the point where they realize like, these are, this is the bias. This is why this study's ineffective, this is why this study is actually deceptive.

3 (1h 34m 40s):
That would be helpful. Here's how they profited off of that study being deceptive. It was responsible for, you know, an increase in their profit margin by X amount. And this is why they did it. These people went to jail. This, these people are being, they left the FDA and immediately went to work for Moderna. This is how much money they made, this is why they made these decisions. And then the ability to read minds all those together, they like, we might be on like the last spaceship that's like shooting away as the earth explodes. You know, that we just make it just outside of the blast radius.

4 (1h 35m 15s):
Yeah. That's the hope.

3 (1h 35m 16s):
That's the hope. The hope is that I mean that, and that might also be the thing that influences people to give into AI and to give into having something integrated into your biology is that it's the only way for us to escape bullshit. Human created bullshit. And when you say trust the science, look, I do trust science. The science is not the problem. It's human bullshit that represents the science. It's human bullshit that's using propaganda and they're using bias studies and they're lying to you. It's human, it's not science and the ideology and the ideological subversion, that's not science.

3 (1h 35m 58s):
That's humans. It's humans and they're bullshit. And if you could just get pure data and pure information, you could talk about it objectively. Everyone should have that. That would be wonderful. But that's not what you have in this day and age with media sponsored narratives. When you have pharmaceutical drug companies responsible for a large portion of the commercial budgets for these programs. And then no one says anything about the 40% increase in all cause mortality that mysteriously arose after they made people get shot up with some experimental shit. Like that's science. How come you're not talking about that?

3 (1h 36m 38s):
Yeah. How come You don't trust that science? Why is that data such a problem? Because that data implicates a lot of fucking people wrong. And a lot of people were giving really bad advice and a lot of people ignored all the warning signs because they didn't want to be an anti-Vaxxer.

4 (1h 36m 53s):
Yeah. The problem is not ever the truth. The problem is what people do with it potentially. Yes. But I think the, the way to approach that is to be honest about what the truth is and then to just say this is what it means and what it doesn't mean. Or this is how it should not be used. And so science is just basically a tool to get to the truth. But when people start, it really bothers me the way that, like you said, trust the science. It's like the science when it fits a particular narrative versus the science as it actually is. So don don't even like to say that I'm s like pro-science so that I follow science because that has such a negative connotation nowadays. Which is crazy because if you can't even say that, then it's like saying I'm in favor of truth and truth means nothing now.

4 (1h 37m 35s):
So

3 (1h 37m 36s):
It's really weird. It's a weird time, but there's enough people that are like actual objective scientists out there. It's just they're captured by these institutions that they find themselves working for. You know? And that's what gets really crazy. And that's where Yuri Beov was so brilliant in explaining what's going to happen, but who the fuck would've thought it was gonna happen with science? Who would've ever thought it was gonna happen the way it's laid out. Like we are our own worst enemy in that regard. And this is also a real problem with people being captured by an idea, espousing that idea, talking to people about it, trying to get people to go along with it and then realizing it was wrong.

3 (1h 38m 17s):
And the long road it takes to accept that and to admit it and then to be open about it. And a lot of doctors to their credit have done that. And you know, I'm sure it was very painful. Like, you know, kind of like coming outta the closet or something. Yeah. Like peel that bandaid away and go, you know what? I was wrong. Like this is, this is not good. This is dangerous. I'm seeing blood clots in people that aren't normal seeing

4 (1h 38m 42s):
Well they risk losing their licensure.

3 (1h 38m 44s):
Yes. Yes. And that's, that's one of the more interesting things about Robert Kennedy Jr's work, particularly his book The Real Anthony Fauci. If you find out how the system actually works and you read that book and how it's been working like that since the 1980s, it's fucking horrifying. Horrifying really? It's really spooky. You know, and I always say that book's not true. Why isn't he getting sued? Why isn't he getting sued? Because it is true. Like you, you, you could go look up, I've looked up many of the things that are in that book and you go, oh my god, this is real. The the testing of vaccines on foster kids for AIDS that killed them in New York. It's like, that's real. Wow. They really did that.

3 (1h 39m 25s):
They, they took these lost kids didn't have parents, they just fucking injected them with experimental drugs.

4 (1h 39m 31s):
I thought it was interesting when he was talking about good mercury versus bad mercury.

3 (1h 39m 36s):
Oh my God. Isn't that crazy?

4 (1h 39m 38s):
Yeah.

3 (1h 39m 38s):
When you find out that the good mercury actually penetrates the blood brain barrier quicker and it fucking accumulating your brain, like what?

4 (1h 39m 46s):
Oh

3 (1h 39m 46s):
Boy. Yeah. There's so many lies because these lies are convenient for profits and that's scary stuff. It really is. I mean that, but that's with everything in our culture. I think the only thing that's saving us is honest discussions. It's the only thing that's saving us right now. and I think that's the thing that they never saw coming, which is really interesting.

4 (1h 40m 8s):
Or that people have the guts to keep going, right? Yeah. I think many people who are trying to suppress this information or suppress suppress information more broadly just think that they could silence the people who are against them. Yeah. But they're very stubborn people out there.

3 (1h 40m 26s):
Well also those people wind up getting fired too, and they wind up getting cast out too and then they wind up like going, oh, what did I do this for? Like we were talking about with CNN, like those anchors, they're fucking homeless now. Like who knows what they're doing? I mean, I'm sure they're not homeless, but they're jobless. Like what are they doing now? Like what, what did you do? And look what happened. Look where it got you. Got you. Nowhere. Like maybe some enough people realize like you can't have a career in bullshitting people anymore. That's not gonna work. There's too many people that call bullshit. There's too many people. And then other people will check, well, who's right? And then when they go over it they go, oh, that guy that you call bullshit on, like he's fucking accurate.

3 (1h 41m 8s):
You're bullshit. You're the bullshit party. And oh look, you're sponsored by all these con Oh, well there it is. Seems pretty obvious now. And that's the thing. That's why nobody wants to listen to mainstream news anymore. And you know, you're talking about like opinion pieces in the New York Times and things along those lines like yeah, those used to be really important, but those are ideologically captured as well now. Yeah. There's less and less of those that I trust now

4 (1h 41m 31s):
When you do see one of those reasonable voices in a mainstream publication, it's like shocking I

3 (1h 41m 36s):
Know like, how long does this guy have to

4 (1h 41m 38s):
Survive? How, how did this happen?

3 (1h 41m 39s):
How, how long is she gonna be working for there? Yeah. It's not good. But also it's kind of interesting because I feel like ideas as well, like almost everything has to have something that's fighting against and

4 (1h 41m 55s):
The push and pull.

3 (1h 41m 56s):
Yeah. And that push and pull, whether we like it or not, we want utopia, but it doesn't exist. We, that push and pull is imperative for growth and change and I think that push and pull that we're experiencing with the, the death of the relevance of mainstream media, at least in terms of television news, is beneficial to, to the rise of independent media. Because independent journalism, there are Matt TBIs and you know, and Sheen Bergers and there's, there's people out there, Barry Weiss, that are really trying to tell the truth and they do exist and you can find them when you've had enough.

4 (1h 42m 31s):
What do you think is going to be the eventual outcome of all those covid narratives?

3 (1h 42m 37s):
Unfortunately, I don't think enough people are going to go to jail, unfortunately. I don't think enough people are gonna be held financially responsible and it'll all be lost if something else happens and they do it again. If something more, more contagious, more deadly comes up and they get to lock down again harder this time and then this time enforce vaccine passports and then connect it to a social credit score and then get people on centralized digital currency, then you have complete ultimate control over narratives because you'll be able to cut people's money off, you'll be able to limit their travel, limit, their ability to work.

3 (1h 43m 25s):
That's a real problem because there's a lot of dummies out there that don't realize the danger of this. And they'll think that, you know, anybody talking about what are you a conspiracy theorist? And they'll get caught up in their stupid mainstream narratives. 'cause a lot of people, they're not paying attention to independent journalism and accurate information. And they're not, they're not sitting around. And we were told like during the pandemic, don't do your own research. Yeah. Like, what the fuck are you talking about? How about my own research in corruption of pharmaceutical drug companies? Are we allowed to do that? Could we allowed to do that about the past? The people that have been responsible for the biggest criminal fines in medical history is that, okay, what the fuck are you saying?

3 (1h 44m 5s):
And, and but the ability to say that just what, what I just said is so critical for people to understand what's really going on. And if you don't have anybody saying that, then we're really in trouble. 'cause if everybody's Brian Stelter, we're fucked. We're fucked. If that's the only way you're ever getting information, there's no Wikipedia. Not even Wikipedia. That's biased too. But there's no independent journalism. There's no substack, there's no YouTube independent journalist videos where they're going over case by case, step by step, all the problems and all of the corruption that led us to this position. If You don't have those people, and all you have is these mainstream propagandists, we're fucked.

3 (1h 44m 50s):
But that's not the case right now. So that gives me hope is that these conversations are happening and people are paying attention and look like, look at how many people are taking this updated covid shot. Fucking nobody, nobody wants that shit. Because they realize like, this isn't work. It's dangerous. You know, everyone knows someone that had something go wrong. Everyone does. And they, we don't even know what the real numbers are. The VA systems, like what does, what does it get like one, 2% of the actual adverse events that are reported? Who fucking knows how many people? I have two friends that have pacemakers. Wow. One, one guy's in his forties, he's almost 50 now. And one guy's in his thirties, thirties, thirties got vaccinated.

3 (1h 45m 34s):
All of a sudden a heart stopped beating for like nine seconds at a time and would just black out and fall down, goes to a doctor. The doctor says you're gonna need to get a pacemaker, at least for now. Oh yeah. That's sad. He's a dentist. He's a very smart doctor. He was like very confused by all this. He's like, I thought I was following the rules. I thought I was following the science. Yeah, it's wild. I'm sure you've seen that video of that girl, Heather McDonald. She's talking on stage about being vaccinated and then she fucking blacks out and cracks, cracks her skull. I see that. Oh God. Tell me the universe isn't trying to send a message through that I mean.

3 (1h 46m 16s):
How is it possible that at that moment, after talking about being vaccinated and bragging about it, that that's when you black out on stage, how many times you blacked out on stage? You know how many times that girl's been on stage? She's been a standup comedian for decades. She's been doing thousands of shows. How many times has she talked about being vaccinated? Probably not that often. How many times she's done it on video? Probably not that often. And the one time she does it, and she blacks out right after she says it and bounces her head off the ground, cracked her skull. But then she was on Dr. Drew and Dr. Drew was talking to her about this is seems to happen when people get boosted there, there's, there's some sort of an effect that happens to people.

4 (1h 46m 59s):
I love Dr. Drew.

3 (1h 47m 1s):
He's out there now. I mean he's, you know, he used to be a lot more mainstream and I think he's kind of woken up to all this shit too.

4 (1h 47m 7s):
What's wildest when people do the compilations of people posting and saying like, you know, I got this and everyone who won't, I hope you die. And then it turns out that they pass after. Oh yeah. Oh, I mean it's, it's tragic. It's, it's sad, but it's also really scary.

3 (1h 47m 21s):
It's very scary. but it's also, they're scared. That's why they post those things. You know, they want to, they want to believe they made the right choice. And I'm sure they've heard all the people that say that it's not the right choice and they wanna fight against that. No, we, I made the right choice. All you people are gonna die and I'm not gonna cry at all. And then you're dead. Whoops. Whoops. Put all your fucking eggs in the wrong basket. Yeah. And you suppressed people that are asking questions, which is crazy, especially when these people are asking questions of people that are, you know, like legitimate scientists. Like I want to know, like, how did you come to these conclusions? What, like Peter McCullough, like that guy is the most published doctor in human history in his field, in his field of study.

3 (1h 48m 13s):
He's not a moron. No. He's

4 (1h 48m 15s):
Very smart. He's a

3 (1h 48m 16s):
Super well respected doctor. And he was talking about the danger of this thing. All of a sudden, this guy is removed from his position at the university. He's getting sued, he's getting like disparaged everywhere. I mean, it's, it's a cra I mean, but it takes people like that. It takes courageous people to stand up and, and just fucking take a chance and, and say, Hey, this isn't right. Like this is not correct. This is not true at great cost personally.

4 (1h 48m 49s):
I think also when people see that someone is willing to take a stand and to say what they think no matter what the cost is, that inspires other people to do the same thing.

3 (1h 48m 57s):
I think it does too. Yeah. It it definitely inspire it, it lets people know that there's another way.

4 (1h 49m 3s):
Yeah.

3 (1h 49m 4s):
You know, 'cause everybody's just stepping in line. It's like, yeah, I'm, I'm, I'm optimistic, but I'm also realistic. This could all go sideways. It could all go sideways. Okay. And, and we could be one of the lost generation and it could take decades before some new generation rises up and pulls us out of this, you know, I mean if you were born in Germany in the 1940s, like how, how would you, what do you, you know, it's not your fault. You're in the middle of fucking Holocaust. Like what happened? You're fucked. You're in the wrong timeline. You just got, and we could be in the wrong timeline.

3 (1h 49m 44s):
Like there, there could be some terrible things that happen in this country where you do get decentralized digital currency and you do get the vaccine passport and you do get a complete capture of the population because you have the ability to shut people's funds off. And most people are just gonna adhere. They're just gonna comply and they don't know what to do. And they're gonna complain. They're gonna bitch and moan and you know, they'll be captured by these massive institutions that only care about extracting profit.

4 (1h 50m 13s):
What I would say is just to, for people to never feel badly about the way they feel or for being skeptical. Because I think that's the biggest thing from, from what I heard in my, from my audience, is that many people felt like they weren't allowed to have their own thoughts or have their own opinions. Like they were afraid of that or they were being shamed for that.

3 (1h 50m 32s):
Yes. Well there was, one of my friends was talking to me about this and he was like, it was in my mind that you have to be an idiot to not take the vaccine. The vaccine is gonna work. They're saying it's gonna work and that's the only thing that's gonna get us out of this. And if these people aren't taking it, they're gonna fuck this up for everybody else. So there was that narrative and my friend was talking about like, that was, he was like, that was me. I really thought that everybody wasn't getting vaccinated was an idiot. And then this is our way out of this. Yeah. and it wasn't. But now he has a completely different perspective. Now he's like, oh shit, they're all liars. Like this is like, and then when you read RFKs work on it and you, you talk, when he talks about the actual studies that they conducted and what they actually showed and that they, they never did a study on whether or not it stopped transmission.

3 (1h 51m 18s):
They never, they had no idea. It was just whether or not it made the antibodies wild. But that is gonna be the case I think with everything that we deal with that involves money. Whether it's climate change, whether it's gender affirmation, surgery, whether it's whatever social issue,

4 (1h 51m 42s):
Diversity, equity and inclusion.

3 (1h 51m 44s):
It's just a money grab. It's all a money grab, you know?

4 (1h 51m 49s):
Yeah. But we hope for the best. Yeah.

3 (1h 51m 53s):
Well maybe this is what I do. I I mean I tell the truth and truth is a money grab kind of.

4 (1h 51m 60s):
I can't tell if you're joking.

3 (1h 52m 1s):
No, I'm not joking, but I'm telling the truth 'cause I tell the truth. But it's also a good way to make money, you

4 (1h 52m 6s):
Know? Well, because that's the thing that's gonna stand in the end. Yeah. You're not gonna have, you're not gonna have to turn around and realize that everything you said was a sham. Right.

3 (1h 52m 13s):
I'm not doing it to make money. Well I definitely am doing it to make money, but I'm not doing it specifically because, oh, I know what I'll do. I'll be a truth teller. No, just, it seems like the thing to do just happens to be profitable.

4 (1h 52m 27s):
Well, because there are so few people doing it nowadays, which is

3 (1h 52m 29s):
Wild. How wild is that? You know? Well you're doing it, you know. Well, back to your work about dating and all this jazz, one of the things that someone brought up to me that I, I was really thinking about the other day was how much everything changed when women entered into the workforce and then when women got birth control. That those, in terms of human history, those are two of the biggest changes when it came to dating. And 'cause now women have their own money and women also didn't get pregnant every time they had sex. Yeah. So they had this ability to move on and not have a relationship with someone that they had sex with and not be connected to them forever because they have a family with them.

4 (1h 53m 14s):
Yeah. Yeah. This is one area I'm really interested in. and I do think that that technology has been, I think Annette positive. I don't think we should want to take it away or take away women's right. Or ability to plan in terms of their, when they want to have a family, if they want to have a family. You know, if they necessarily want to have, what am I trying to say here? Yeah, I think just the ability to control their, their sexuality. Right. Not to not have their sexuality necessarily linked to reproduction. Right. I think that's a powerful thing. I'm sure many people disagree with me that we should separate those things, but I otherwise, the alternative is to say that people should not be sexually active until they're ready to have children.

4 (1h 53m 59s):
Which I don't think is realistic. No. For men or women. So I, there definitely has been a lot of change in society in terms of now, like you said, because women are basically, before it was that women were seeking equal opportunities in terms of education and employment to men. And now women are, for the most part, at least in the west, outperforming men in many cases, especially when it comes to education. You know, they're graduating high school and university at higher rates than young men are. and I think the projected ratio is that women are gonna be graduating from college at a ratio of two to one to men in the coming years. That's

3 (1h 54m 37s):
Amazing.

4 (1h 54m 38s):
So, and Of course, I'm not saying I think women should go back to being in the kitchen or that women aren't good at science and math and people accuse me of these things, but I think it's worth talking about and I think we do need to take into consideration helping men who may not feel like they're doing as well in society or think about real solutions as to what we can do to help them. Because if you are a woman, you and you know you're straight, you're going to want to date and hopefully settle down with someone. And if you can't find a partner, that's not a good thing either.

3 (1h 55m 5s):
Well, there's also a difference between the way a woman perceives and what a woman wants from the world versus a man. And that's why you don't see male fuck robots.

4 (1h 55m 15s):
Well I was gonna say that's also why you don't see male house husbands that much, although that's like a trend on social media.

3 (1h 55m 21s):
Oh, there's a few of those.

4 (1h 55m 22s):
They're But women, women are sad man. Women aren't happy with them though. No. They might pretend that they are, but they're not. No. But yeah, it's same thing. You don't see male sex robots so much. No. Unless it's for gay men.

3 (1h 55m 32s):
Yeah. Maybe. Are there gay men robots for sex?

4 (1h 55m 37s):
Yeah, they're, well they're dolls and I'm sure the robots are on their way. They're on their way. Yeah. Can't stop them.

3 (1h 55m 44s):
Jack Thor robot waiting for you at home every day basically. Yeah. Yeah. The house husband thing's a wild one. It's, it's like that, that gender role seems to be very pervasive. Like the, the, the, the male provider versus the female provider. don don't know anybody that's in that female provider man who just sits at home thing where it works.

4 (1h 56m 7s):
Well. You see those videos, the men like, they're like doing the dishes and vacuuming while they're girlfriends at work and I think that's great. I think men should do housework. I don't think it should be just the woman doing that and having a job. But women want, like women prefer typically men who provide and

3 (1h 56m 25s):
Yeah. don don't think are

4 (1h 56m 26s):
At least as successful as they are

3 (1h 56m 28s):
Typically. I don't think most women want a man who doesn't have his own money, who doesn't have a way to make an income and just like, you're just, it's gonna be a fucking weird relationship. You know? It's gonna be weird.

4 (1h 56m 41s):
It is cute though when they pack their wives their lunches I guess.

3 (1h 56m 45s):
Well look, it'd be cute if you had money. Like if it was a guy who is wealthy and just did that because he loves you. Yeah. Yeah. But not some bitch ass man that doesn't have any other function other than to be your little, your little keeper. You know, that's I think part of the problem. It's just, it's, there's certain gender roles. I'm not saying you should adhere to them. I think you should do whatever you want. If you're a woman and you wanna be a power line worker, go for it. Yeah. Of course you should be able to do whatever you want. But there are certain gender roles that are stereotypes for a reason. You know, like there's women that have zero problem not making any money and being a housewife.

3 (1h 57m 25s):
I don't know any man who does that, who's not conflicted or or cued or beaten down by that relationship to the point where, you know, like you just, it's, it's just not normal.

4 (1h 57m 38s):
Well in the past it's because evolutionarily, if a woman was with a man who couldn't provide, they would probably both die. Right.

3 (1h 57m 44s):
So yeah,

4 (1h 57m 45s):
They probably both die. There's a reason for that. There's a reason why you know, that that tendency still remains. Now

3 (1h 57m 50s):
Of course you want a man who can protect you. You want a man that can provide and you want someone who can step up when shit gets weird. You know? And if, if you don't have someone who can respond to a a dangerous situation or to pressure or can think clearly can handle stress like what? You got a liability now you got someone who's gonna fall apart. Now you have the opposite of a provider and a protector. You have some fucking extra person that's more of a liability than you are like Oh great. and I have to abandon this loser and run from the zombies 'cause he is crying. Yeah. But again, I think people should do it at, look I'm friends with a lot of females that are MMA fighters, you know?

4 (1h 58m 34s):
Oh yeah. Of course. I have no issue with gender nonconformity. Yeah. I think if men want are more feminine or women are more masculine, that's

3 (1h 58m 38s):
Fine. Absolutely Nothing wrong with it at all, you know. But I just think in terms of traditional heterosexual relationship roles, I'm not saying it can't work out if the woman has all the money and the man is just laying around at home All day. I'm just saying it's not likely. Yeah.

4 (1h 58m 54s):
Or for me, just, I bring attention to this because when you see those dynamics where people are trying to go against what they inherently feel, they don't understand why they're not happy. And it's like You don't have to deny what you want in the name of being progressive. Yeah. Or trying to be enlightened. It's okay to, if you do fall into stereotypes, that's okay. And if you naturally don't, that's fine too. But I don't think we should necessarily intentionally try to push against stereotypes just for the sake of it. Right. Because there's a good chance you're not going to be satisfied with that.

3 (1h 59m 20s):
That's a good point. Like there's nothing wrong with a feminine woman. There's nothing wrong with a masculine woman. There's nothing wrong with a masculine man. There's nothing wrong with a feminine man. It's like, but when you see a feminine woman, like an o overtly feminine woman, there's some people are like, oh, she's giving into stereotypes. Like maybe not. Maybe that's what she likes. Because isn't it, is it, if it's, if there's fucking hundreds of millions of them, isn't it possible that that's just a way that someone's hormones and personality and, and interacts with the world. And then there's the other thing that's odd that I've always wondered 'cause it's like it doesn't affect men physically.

3 (2h 0m 1s):
The the birth control pill. Like what kind of an effect has that had overall on the way women behave and the choices that they make? Not just because they have choices because they don't have to worry about getting pregnant, but they're, they have this hormone that's being artificially introduced into their body that tricks them into thinking that they're pregnant. Which is a very unusual state. Well very common, but a very specific state of the, the woman's body. And now your body is like that all the time. Yeah. Which has to profoundly affect decisions you make the way you live. Like my friend Whitney Cummings, she got off birth, she just had a baby.

3 (2h 0m 43s):
She got off a birth control pill and she was on the pill for like 20 years or whatever and she's like, Jesus Christ. It was like, like I'm a different person. Yeah. Like what the fuck happened?

4 (2h 0m 53s):
Yeah. That's really common. I hear that a lot. Pretty much every woman is going to be on birth control on her at some point in her life. Not necessarily a pill though. She'll be using some form of birth control. But I would say definitely in terms of the pill, because it tricks your body into thinking you're pregnant. Right. There has been research to show that women who meet their partners while they are on the pill and then they get off it, they're not attracted to them after. That's

3 (2h 1m 16s):
Crazy.

4 (2h 1m 17s):
And so I know and I feel really badly for those guys. I feel bad for the women and for the men. 'cause it's like, how sad would that be? Especially if you start, you know, having a family and you realize you're not attracted to them. Well

3 (2h 1m 27s):
What is it about them that's not attractive once they're not on the pill?

4 (2h 1m 31s):
Well, because when the body is pregnant, you're seeking, I'm, I'm treating it like this is a totally disconnected thing from someone like when the body is pregnant, but when, when someone is pregnant or when when they're on the pill, they're seeking someone who's gonna be more nurturing. And versus when you are not on the pill and you're actually ovulating you during that period, you're looking for more of an alpha type super masculine guy. Because that's someone who, that's a man who's gonna have good genes that provide you with your offspring.

3 (2h 1m 59s):
Interesting.

4 (2h 2m 0s):
So they might choose a guy who is more, say, sensitive or more nurturing while on the pill and then they get off it and then they want the more alpha type guy. Which, you know, I can see why some people might find that offensive because that seems to fit into certain stereotypes about women, what women do and don't want. But I think it's fine if men are masculine. But why

3 (2h 2m 24s):
Is that offensive?

4 (2h 2m 25s):
Well, because I think for women

3 (2h 2m 26s):
To, it's so common

4 (2h 2m 27s):
To say that women want a masculine man, which I think most women do. I think pe some people feel it's saying that women deserve to be treated badly. and I don't think masculinity is necessarily a bad thing. It's only if someone is an abusive person. Right. That that's a bad thing. Yeah. But those two things are not necessarily found together. Masculinity doesn't necessarily mean that someone is going to treat his partner poorly or I think also communication. Right. Masculinity, when they use the term toxic masculinity, they're referring to men not wanting to talk about their feelings and having mental health issues because they bottle things up. And

3 (2h 2m 60s):
There's that for sure.

4 (2h 3m 1s):
But there's a middle ground, you know, I don't think we have to demonize men just like we don't have to demonize femininity.

3 (2h 3m 6s):
I couldn't agree more. Yeah.

4 (2h 3m 8s):
But I, I'll have so much more to talk to you about this once I that it's what I'm working on. Well,

3 (2h 3m 13s):
Well we'll definitely do it again once you announce what you're working on. Thank you. Do you wanna do it that way? We can do it that way.

4 (2h 3m 18s):
I would love that way.

3 (2h 3m 19s):
Is there anything else you wanna talk about?

4 (2h 3m 21s):
I could go forever, but I think that's, I got my, my huge list here for your audience wants to, where's the camera? Because they wanna see how organized I am. Okay.

3 (2h 3m 28s):
Well if people also, if they wanna follow you online, tell people what's the, the best access to your work and where should they go?

4 (2h 3m 35s):
Yep. So you can find me on social media at Dr. Debra Soh. Debra is D-E-B-R-A. So is SOH. You can, I actually have a book, my book here if they wanna see this hateful, transphobic piece of work. The End of Gender. You can get at Dr. Debra, Dr. Debra so.com and Simon and Schuster's website. Thank you Joe. Thank you. My pleasure so much. You've been so supportive from day one. I remember coming on your show when I was, when you're still in LA and I was just like, I really hope that he doesn't think I'm a crazy person.

3 (2h 4m 5s):
No, I don't think you're a crazy person. and I always enjoy talking to you. Thank you. So best of luck to you. Thank you. And we'll do it again. We'll do it again when you're this not to be mentioned project. Awesome. Okay. Thank you. Bye everybody.