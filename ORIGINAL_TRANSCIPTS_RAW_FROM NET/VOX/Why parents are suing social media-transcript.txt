0 (1s):
Congress has tried and failed for years to regulate social media companies, but now there's another group taking them on. Parents,

2 (11s):
He was so addicted to it that his last moments of his life was about posting on social media.

0 (19s):
And parents aren't alone. They're joined by school

3 (23s):
Districts. Kenosha Unified Schools are joining a national lawsuit, accusing companies like Facebook and Instagram of maximizing profits at the expense of kids mental health

0 (33s):
And even state governments.

4 (35s):
Today we announced along with the Attorney General here in Arkansas, that we we're filing three lawsuits, two against TikTok, one against Meta because of the deceptive practices that they have engaged in

0 (47s):
On today explained, we're gonna explore a new legal argument suggesting that social media algorithms are causing mental, physical, and sometimes lethal injury to kids.

5 (60s):
Here's a pop quiz. What's a better factor to determine upward mobility? A elementary school test scores b, A two-parent household, or C commute time.

6 (1m 11s):
We know that social mobility depends on literal mobility.

5 (1m 17s):
Transportation, secretary Pete Buttigieg on the weeds referencing a 2015 Harvard study. I'm John Plin Hill host of the Weeds, a podcast all about the policies that shape our lives. Find it wherever you get your podcasts.

7 (1m 31s):
Since Trevor Noah left the Daily Show, there have been a lot of fill-in hosts like Roy Wood Jr. He's one of the show's correspondents, and he is not shy about his intentions.

8 (1m 42s):
We are all openly saying we want the job. I don't think there's a single co, I'm just being straight up. I don't think there's a single.

7 (1m 49s):
So you want the job.

8 (1m 50s):
That's Ben. If they offer me that job, I'm taking it. Okay? Now I don't know what the hell I'm gonna do with it, but I take that job.

7 (1m 56s):
Roy Wood Jr. On maybe hosting the Daily Show. Also how he's preparing to host the White House Correspondent dinner this week on Intuit Vultures Pop culture podcast

1 (2m 13s):
You're

9 (2m 13s):
Listening to today explains this is, is it today? Explain or try explains, explain death. Explain death

0 (2m 20s):
As much as you wanna believe. Otherwise, the kids are not okay. Rates of self-harm and suicide are up over the last decade and the root causes range from the pandemic to gun violence to climate anxiety, to of course the internet. And now a slew of personal injury lawsuits around the country are going after social media companies. Previn Warren is one of the attorneys leading a lawsuit in California that represents over 150 kids and their families. He says the owners of Instagram, Snapchat, TikTok, and YouTube are knowingly getting kids addicted to their platforms. Part

10 (2m 59s):
Of how it works, it's very similar to a slot machine, it's a psychological principle called intermittent variable rewards. Basically when you pull a slot machine,

1 (3m 10s):
You never know what you're going to get.

10 (3m 15s):
Maybe you're gonna hit gold, maybe you're not, but the frequency with which you get a payoff is indeterminate, right? You don't actually know when it's gonna hit gold or when it's not gonna hit gold. And so that compels you to keep pulling the lever and playing over and over again in order to sort of get that dopamine hit. Instagram and TikTok work very similarly. They study exactly what you hover over and for how long they study what your likes and comments are. And when I say they study, I mean the algorithm is really processing that data in real time, right?

10 (3m 58s):
And they use that information to design your feed in a way that gives you a payoff, but on a variable and unpredictable schedule, right? And that actually is the most addictive way to set it up, kind of like the slot machine. You don't know what you're gonna get and when you're gonna get it and it keeps you scrolling.

0 (4m 19s):
But creating an addictive product isn't necessarily illegal. So Previn team is drawing on an old legal concept to make an unexpected case.

10 (4m 29s):
It's an interesting case in the sense that we're bringing principally a products liability claim against these companies. So products liability is a legal concept that's, you know, 50 years old. And the idea is that if you manufacture or design a defective product, you should be held responsible if that product winds up hurting people. And so we've applied that concept, we've sort of dusted it off and, and repurposed it in the 21st century and applied it to these social media apps. The algorithms that power these apps are addictive. And what we're really beginning to understand that I don't think the public is understood up until now, is that the fact of addiction is something that these companies have really been aware of.

10 (5m 15s):
At least Meta has been aware of it, and their company documents show that we haven't gotten too far into the case yet. But what we're already seeing is disturbing. It confirms what the Facebook whistleblower Francis Hogan leaks to the press at the end of 2021.

11 (5m 35s):
Facebook understands that if they want to continue to grow, they have to find new users. They have to make sure that that the next generation is just as engaged with Instagram as the current one. And the way they'll do that is by making sure that children establish habits before they have good self-regulation. By hooking kids, by hooking kids

10 (5m 56s):
Through that addictive mechanism. Young people wind up in really dangerous rabbit holes that cause them to have serious body image and self-esteem issues. And so our clients have developed really serious eating disorders, suicidality, and in some really tragic cases have actually taken their own lives and were assuming on behalf of their estates or, or for their parents.

12 (6m 21s):
My name is Rosebury. I am the mom of a teenage daughter who has been diagnosed with anorexia nivo, a restrictive type. Her disorder began in 2020 when she was 14 years old. And we are still going through that process in recovery now in 2023,

10 (6m 46s):
Another meta employee that described kids saying they often feel addicted and know what they're seeing is bad for their mental health, but feel unable to stop themselves.

12 (6m 56s):
I wasn't aware of it until she went to residential treatment and I actually had her phone and then I did look at her Instagram account and found that it was frightening. I found images of some really thin emaciated looking teenagers in bikinis showing off their bodies and telling other people how they should look like them.

0 (7m 28s):
How much of this is on parents? How much of this is buyer beware? You know, kids sign up and it's a free for all. Just like the rest of us, when we got 56 k 25 years ago,

10 (7m 39s):
I think the, the social media companies really wanna point the finger at parents, but they're completely outgunned. Most parents had no idea what they were in for when they got their kids a phone.

12 (7m 48s):
When she first got her phone at 11 years old. We were not aware of the applications that kids had access to and that she was constantly seeing photos of other teens body images. She was getting tips and tricks on how to hide her eating disorder. So I believe that it did cause her to spiral into that addiction.

10 (8m 22s):
You can give your kid a phone for completely innocuous and reasonable purposes. Like you want your kid to stay in touch with you when they're on the bus route home, right? You don't realize that you're giving your kid this license to be exposed to all kinds of nonsense and to be subject to these apps that are demanding their near constant attention. And, and we have clients, parents that try to take the phone away or try to disable the apps and the kids experience classic withdrawal symptoms just as if they were being taken off of a drug or trying to taper off of nicotine use. They'll, they'll throw things, they'll hit things, they'll, you know, they'll hit their parents, they'll hit them, they're destructive.

10 (9m 5s):
They'll, I, I mean, I'm, I'm really serious about this. I'm not making it up. And so the parents say, you know what? I'd rather just give the kid the phone because that's even worse, right? And yeah, kids just cannot get themselves to disengage once they're in this cycle of compulsive use.

0 (9m 23s):
What does suing all these companies meta Google, snap by dance get us, what's the manifestation of a win here?

10 (9m 32s):
Well, there's a lot of different ways to imagine what that looks like, but you know, one way to think about it is to wind back the clock. When Instagram was first released, it was, you know, for latte art, right? It was for vacation photos.

0 (9m 47s):
I miss, I missed those days, I missed that version of Instagram.

10 (9m 50s):
Well, I do too. And so then you have to ask yourself what changed? Why did it become the really negative pervasive social phenomenon that it became? And the reason is that the algorithm changed, right? The, the core workings of the product were modified to prioritize photos and videos that keep people on the app as long as possible, right? Your, your feed's not organized chronologically. It's not organized by, you know, what your friends posted. It's organized in a way that is giving you the stuff that the app has predetermined through its algorithm are gonna keep you engaged, which means using it, right?

10 (10m 33s):
Because that's what drives the ad revenue and that's what makes meta money. It doesn't have to be designed that way and in fact it wasn't at one point in time. So that's a change we could see is change the algorithms so that you know, maximizing engagement, you know, which means creating compulsive and addictive use that's no longer how the algorithm works.

0 (11m 2s):
Krevin Warren is an attorney at law. He's going up against some of the biggest companies in the world. We reached out to them all, snap meta, Google bite dance. They all said something like, we prioritize safety for kids except Bite Dance, which owns TikTok. They didn't say anything at all. Google, which owns YouTube pointed to Family Link, a feature that allows parents to limit screen time and block specific types of content on supervised devices. Snap, which owns Snapchat obviously said it uses human moderators to catch harmful content before it spreads to large audiences. It also has a similar tool to Google's called Family Center, which allows parents to monitor who their kids are communicating with.

0 (11m 48s):
Meta, which owns Instagram said they've invested in technology that finds and removes content related to suicide, self-injury and eating disorders before anyone even reports it to them in a minute. The science of what social media is doing to kids, it's today. Explained

Coda.io (12m 11s):
Support for today's show comes from Koda. Koda might be able to help your team run more efficiently. Koda is a doc where teams can work together on projects from start to finish with everything they need in one place. Documents, spreadsheets, workflow tools, all in one location regardless of format I'm told with Koda, you're never gonna have to ask where are the latest project updates or where the performance stats are at or whether there's a report about licenses you can see or other businessy type questions. That's the kind of inefficiency that slows down productivity and collaboration with Coda, your team can operate on the same information and collaborate in one place to get your projects across the finish line faster. Your team might be able to run more smoothly and more efficiently with Coda. Listeners can try Coda today for free by going to coda.io/explained. That's coda.io to get started for free coda.io/explained,

Wondery (13m 12s):
Free speech is essential to a functioning democracy. Do you believe Twitter rigorously adheres to this principle? What should be done is a new platform needed is Twitter dying. I'm David Brown, host of the new Wondery podcast, flipping the Bird, Elon versus Twitter. Join us as we unravel the fascinating story of Elon Musk's unexpected bid to buy Twitter and all of the drama that has happened since then. Those still employed at Twitter. Soon saw the company and its culture morphed into something they didn't recognize. He laid off 75% of the Twitter workforce, reinstated exceedingly problematic and dangerous users and even encouraged his staff to sleep in the office. Ex-employees, Elon's critics and fellow CEOs were quick to announce him as an in over his head rich guy. Is Elon all talk or are his unruly methods actually the work of a genius? Follow Flipping the bird, Elon versus Twitter. Wherever you get your podcast, hey prime members, you can listen to episodes ad free on Amazon music. Download the Amazon music app today.

16 (14m 13s):
Look what I just posted brunch with these two dumb

17 (14m 17s):
Ups. Oh my gosh, so good. Is this good? I said Sunday Fun with these idiots. Yeah, that's good. That's great.

0 (14m 22s):
Today explained is back previn, the lawyers suing social media companies is gone. His case hinges upon whether social media is damaging to kids' mental health. So we wanted to find out what the science says.

18 (14m 36s):
My name is Dr. Mitch Princeton. I am the chief Science Officer of the American Psychological Association. Dr.

0 (14m 41s):
Princeton's studies how kids interact with one another including online. So I asked him a simple question, is social media ruining kids' lives?

18 (14m 51s):
Yeah, if you ask a scientist a simple question, you're gonna get a really complicated answer I'm afraid. But you know, social media is not all good. It's not all bad. It's an interaction between who you were before you logged in and what kinds of things you're doing on there. And the products of those two pieces could lead to vastly different outcomes, you know, from kids, a kid. And

0 (15m 14s):
When we're talking about kids, vaguely what, what age level are we talking about?

18 (15m 18s):
So we're really talking about kind of that pre-adolescence and that adolescent period mostly. So we know that adolescence around the time that puberty starts, maybe a year or two before that, we see huge increases in the risk for depression in general. We see huge increases in rates of self-injury. Like cutting is a really common example. We see increases in more what we call disruptive behavior, acting out aggression. And usually this is when we see a lot of increase in what we call health risk behaviors. Whether it's risky behaviors to change your body shape or things like substance use.

0 (15m 55s):
And so, but these behaviors you're talking about, how do they connect if at all to social media? Do we know? We're

18 (16m 1s):
Starting to figure that out. I'll say in short that it's not so much how much kids are on their devices or using social media. It really is about the specific kinds of functions or the specific types of content that you can find on some platforms.

19 (16m 18s):
It depends on which you allow yourself to see who you follow, who you don't follow. What's on your explore page is just what you make it.

18 (16m 29s):
So the kinds of things that we're concerned about when we think about the content that kids are experiencing on social media are content that's exposing them to discrimination and hate content. That is literally teaching them how to engage in psychologically disordered behavior like cutting or substance use and how to hide that behavior from their parents.

0 (16m 50s):
But you're talking about phenomena that sort of predates social media. What's changed since kids have started spending hours on end on TikTok or Instagram? There's

18 (17m 1s):
Something about kids being able to communicate now, first of all, predominantly on social media it doesn't supplements, it's really taken over for most kids, the majority of their social interactions. It's

20 (17m 14s):
A lot easier to just meet up with people wherever you are as long as you have a way to connect with them. So whether that be texting or Snapchatting or calling them. But

18 (17m 24s):
Also scientists have characterized kind of aspects of social media, like it's asynchronous, so you're interacting with folks not in real time. It's permanent, it's very visual. There are ways in which it creates stress because you can quantify how much people like you or like what you said or or don't like you.

21 (17m 43s):
People that I know actually worry about how many followers they have compared to other people and like if they're not getting as many messages and it just causes so much unnecessary drama, I

18 (17m 53s):
Would say. But maybe also particularly important is the work of algorithms and machine learning here. You know, for the whole history of our species, and we're only here because of our ability to be a social species, is this is the first time we've ever outsourced our social relationships to a computer. The computer now picks who our friends are, who we, whose posts we read in what order. It really guides us in a way that again, can be very helpful, but also we're giving up a lot of control. And for teens who have pretty immature developing brains, you know, when they usually get started on this.

18 (18m 33s):
That's a question that scientists are really interested in understanding more.

0 (18m 37s):
Where are you sort of heading in in your scientific study of how an algorithm can sort of shape the brain of an adolescent? Well,

18 (18m 47s):
One of the things that we're starting to see in the science is that the area of the brain that's activated on social media is kind of that area where it gives you a dopamine and an oxytocin response when you are being agreed with or getting attention or feeling like you're being liked.

22 (19m 5s):
I think we're influencers because some people our age or under our age look up to us. When people look up to you feel good about it sometimes

18 (19m 16s):
That's all fine. It's just that that's really close to areas that motivate us to engage in more and more of that behavior. And that can lead to what, as scientists, we stay away from the word addiction, but we do talk about problematic social media use where kids are spending far more time online than they even want to.

23 (19m 37s):
Me and my friends are on this, our phones a lot at the same time. I honestly don't really know why we do it while we're together, but we do,

18 (19m 46s):
They can't stop even if they want to some report and they're experiencing withdrawal symptoms. So it's affecting their homework, their relationships, and perhaps most importantly their sleep. And the reason why sleep is especially important is because sleep is really needed for the adolescent brain to grow to the size that it's supposed to be. So when you have disrupted sleep, we're seeing that that is actually affecting brain size in adolescents. These algorithms, you know, are designed to keep us engaged as much as possible. But when a teen is staying up till early hours of the morning watching videos or reading others posts, that then has a direct implication on really how their brain is growing.

18 (20m 28s):
I

24 (20m 29s):
Only use Instagram now. I've stopped using Snapchat as of like January. I just found myself getting really anxious about things. So I decided, you know, I'll just take a break from social media. We're

18 (20m 39s):
Starting to hear that a lot of kids are experiencing a remarkable amount of stress from their devices. It notifies them too often. There are too much information that they're trying to digest all at once, and they're really concerned about what they'll miss out on if they're not online. And if they are online and they post something, they're very concerned how that will be received. About 50% of kids are now reporting that they're experiencing so much stress that it's interfering with their day. And the more stress they're experiencing, the more depression they report. About a year later, About a year or two before you notice that a kid's body is changing and growing up, the brain has already started doing its work and one of the first things that it does is it starts to develop more of an adult-like brain in an area that makes us crave social rewards.

18 (21m 29s):
That feeling of getting attention or influence or power or you know, positive feedback from our peers. We don't know exactly why, but it might be because the brain is kind of preparing kids to be more autonomous. So you know, the brain is kind of encouraging you to want to hang out with your peers a lot more and roll your eyes at your parents, which is what we all see happens when your kid is around 11 or 12. And we don't just see this in humans, we see this in other mammals as well. There's that tendency to want to hang out with adolescents. Well the reason why that's important is because teens are then around 12, 13 years old. They are very, very much craving this peer interaction and for, you know, about 60 to a hundred thousand years.

18 (22m 12s):
The only way you can get that was by going to school or by going to their house or maybe at some point picking up the phone and calling them. Now it's different now kids can satisfy that urge, they can scratch that itch by pressing buttons on a device 24 7, 365. The brain wasn't built for that. So we're a little bit trying to figure out what is the effect of taking a kid who is, their brain is built to crave that kind of interaction and now giving them the opportunity to get it far more than we ever expected, even with a quantified tally showing them how successful they are doing it.

19 (22m 54s):
I have 316 followers and then most of my friends have like a thousand or like 600.

18 (23m 1s):
This is a little bit of a perfect storm where we've got adolescents brains craving something and now this brilliant technology that allows them to, to get it far more than we ever had expected and we've ever before, been able to in the history of our species, we're also learning a lot of positive aspects. Kids are having real friendships with kids that they might never meet. And those friendships do in fact serve a buffering function to help them in times of stress, maybe even make them less suicidal in some cases.

25 (23m 31s):
Sometimes when I'm sad, I like to communicate with my friends on social media and that really makes me feel less lonely.

26 (23m 37s):
Yeah, I never really feel depressed or anything like that just because there's always somebody to talk to and always somebody that's there for you. That's kind of a good thing about social media.

18 (23m 45s):
Kids also have more diverse friendships online than the friends that they're able to meet offline or in real life. And of course that's a great thing if kids are being exposed to, you know, more diversity online as well.

0 (23m 58s):
You're painting a complicated picture here. They're clearly positive aspects of kids spending a lot of time on social media. They're developing friendships, they're encountering people and things that they would not usually encounter. But then you're also saying there's a risk of kids getting addicted. There's the risk of kids not sleeping enough, not having their brains fully develop. There's a lot going on here. Is there any scientific consensus on how social media relates to mental health and adolescents? Well,

18 (24m 26s):
I think we're seeing both the risks and the benefits and we're gonna have to set some controls or some systems in place to make sure that adolescents biology doesn't get the better of them and they're able to do this in a safe way that optimizes the benefits and minimizes the consequences. Social media is now one of those kinds of behaviors. We should be teaching kids about this in school. Help them be smart consumers. We should be teaching the parents about the science so they can make the best decisions for their kids and we should, you know, consider whether there are some systems we need to put in place, whether legally or informally. So that way we're able to protect kids who are engaging in this in a more vulnerable way than adults would.

18 (25m 15s):
We frequently work with kids and tell them to consider, why would a company invest billions of dollars and and thousands of brilliant minds to offer you a completely free application just to hang out with your friends? What is the, what is the motive there? And when they start to realize that someone's making money off of what they do, maybe their data, maybe that's why they're encouraged to stay on as long as possible. It really helps kids to realize, wait a minute, let me take control and figure out how do I want to use this? What are my goals? How do I know when I have stopped? I've reached my goal and now I'm just giving someone else my brain for profit.

0 (26m 4s):
Dr. Mitch Princeton, he's Chief Science Officer at the American Psychological Association. Hema Shaw produced our episode today. She had help from Jolie Myers, Laura Bullard, Michael Rayfield, and Paul Robert Mosey. We use some footage from Common Sense Education in the show. Thanks. Common Sense Education. I'm Sean Ramas firm. This is today Explained.