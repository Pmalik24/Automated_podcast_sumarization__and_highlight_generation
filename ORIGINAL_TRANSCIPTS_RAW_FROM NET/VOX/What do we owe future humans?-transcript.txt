1 (2s):
Charity philanthropy giving these have been around for maybe as long as some people have had more than others, a movement called effective altruism claims it has improved on the original mandate. Give to give, well, I E be smart about giving. Make sure it counts. Recently. This movement has gone from relatively niche to mainstream. Consider Dylan Matthews. He's a senior correspondent at box who started writing about effective altruism EA a decade ago, he became an adherent and he did something that's big in EA ethos. He donated a kidney to a stranger.

2 (43s):
You meet a lot of people to talk a big game about doing the right thing. But once I started meeting people who talked a big game, but also would go under the knife for it, that really made an impression on me.

1 (53s):
The rise of effective altruism coming up on today explained

Citi (60s):
Net zero carbon emissions, zero racial wealth gap, zero poverty. Those are ambitious goals and to help reach them, the world needs to take action that together cities committed $1 trillion in sustainable finance by 2030 to facilitate innovative solutions like renewable energy and clean technology and provide access to essential services like education, health care, and affordable housing. They're also helping close the racial wealth gap and increase economic mobility in the us. It takes everything to reach a zero for the love of making a difference for the love of progress. Learn more at citi.com/e S G

Smartsheet (1m 43s):
Process. It's a small word with big implications because whatever an idea starts, a process gets done. It's how big talk drives real action and people achieve their best work at Smartsheet. We're in the process business, the go-to for managers who love pulling in the right combination of data tools and people from across the company to make it happen. One platform, every project, any scale, it doesn't get bigger than that. Smartsheet power, your process visit smartsheet.com forward slash power. Your process

1 (2m 19s):
It's today explained Dylan Matthews Vox, senior correspondent. What is effective altruism?

2 (2m 26s):
Effective altruism is a life philosophy slash social movements that emerged about 10 years ago from a group of philosophers based around Oxford. And the basic premise is that people could be doing a lot more to help others and make the world a better place than they are, and that they should try to do that in as cost-effective and efficient a way as they can.

1 (2m 51s):
So do good and don't be wasteful in doing good. That seems pretty old school, but you're saying there are some new things tell about one thing that makes effective altruism or EA different.

2 (3m 5s):
The most important one I think was, was the focus on effectiveness and the idea that there were huge differences between the most and least effective thing you could do with your money. When I was raised in my church and I was in a fairly liberal Episcopal congregation, we were never like crunching the numbers and saying, well, we could do this thing on, on hunger in our community, or we can do this thing on homelessness, but this, this would get this many people housed. This would get this many people fed. And that from day one has been a key part of the EA.

5 (3m 33s):
So this, this question about how best to give is something that I've thought about a lot and the organization that I founded and that I'm the president of giving what we can has been set up to really address

2 (3m 49s):
Part of the origin story is that the Toby Ord, she was one of the philosophers at Oxford who founded the movement. There's some key, inspirational documents. One of them is this Blong report comparing cost effectiveness of global health interventions. So if you're a program officer who has like a billion dollars to disperse, do you give it to buying dialysis machines and Ghana, or do you spend it on bed nets or do you spend it on vaccinations? I had a vague sense that you should, you should give back. You should do a good thing, but how you do it doesn't matter. And I think one of the big insights of VA as a movement was know how you do it matters a lot.

5 (4m 26s):
So here's a, here's a simple example though, to start off with, so it costs about $40,000 to provide a guide dog to someone. This is one way that we can try to combat blindness in a developed country. In contrast, it costs about $20 to completely cure someone blindness caused by Tacoma.

2 (4m 43s):
And we could make a lot of gains by just shifting some of the Goodwill that we have now toward more effective directions, as opposed to trying to increase the total amount of Goodwill in the world. Not that that's bad, that's very important, but that the effectiveness and how you do it matters a lot

5 (5m 0s):
For a given donation. Let's say a $40,000 donation that could either provide one guide dog to someone who's blind and help them get through their life. Or you could completely cure 2000 people of blindness. This is an example of the kind of disparities you can get in terms of impact

1 (5m 16s):
It's data-driven. And in some ways that makes it seem almost inevitable in 2022 in a time where, like we have information on effectiveness in ways that we just couldn't 30, 40, 50 years ago. Tell me a bit more about the intellectual lineage of effective altruism. Where, where did this begin?

2 (5m 35s):
The two big influences were an essay from Peter singer named famine, affluence and morality, and a book from Peter Ungar named living high and letting die singer was writing in the early seventies during the English mushy independence war

6 (5m 50s):
After a night bomb raid on DECA, the search for the bodies in the wreckage of an office.

2 (5m 54s):
There's massive hunger. Pakistan was committing really horrendous war crimes and there was massive efforts needed

6 (6m 2s):
Estimates of the dead vary 200, 400 and more nobody will ever know for sure.

2 (6m 10s):
Singer made an argument using a now familiar thought experiment of, of man wearing a suit, walking by a lake where he sees a child drowning. And his argument was we would condemn that man for not rescuing the child because he was late to a meeting or he didn't want to muddy his clothes. That would be appalling to us. And his argument was that as long as there's widespread suffering of the kind he was seen in Bangladesh in poor countries,

7 (6m 39s):
There are things that we could do to help them for something like the cost of an expensive pair of shoes, and yet most people are not doing. And so if you're going to condemn the person who fails to save the child, because he doesn't want to incur the expense of replacing the clothes, then don't you yourself have to at least donate the cost of a pair of expensive shoes and clothes to those organizations that are helping the global court.

2 (7m 10s):
This was I think, a very influential argument within philosophy. It's a really bracing argument and had real practical implications, which is not always true in academic philosophy. And Peter Ungar, a couple of decades later, tried to sort of add some heft to it. And you wrote a whole book trying to defend this view against all the counterarguments that had emerged. And so I did philosophy in college and I was assigned these books. And so I do have these arguments, but there was no like organization around them. You read them in your life. You should like help people in poor countries, but there was no like action plan after that. And I think part of what effective altruism was, was an attempt to take those arguments and develop an action plan around them.

1 (7m 53s):
Tell me about some of the things that you've done that would fit in this rubric of effective altruism.

2 (7m 59s):
Yeah. I mean, I would identify as an effective altruist. I think the two big things that changed in my life as a result of incurring this, where I took the giving, what we can pledge, which is a pledge from the movement to give 10% of your income for the rest of your career to highly effective charities. So I've been doing that for, for a number of years now and tend to keep doing that. I also sort of inspired by a couple of people I met through EA donated a kidney about six years ago. I, I got a letter from my recipient. She was on dialysis for 15 months. I'm in relatively good shape physically and have high hopes to now live perhaps 20 or 25 years with the kidney, which you so graciously gave, which was an excellent match for me.

2 (8m 48s):
Let me say it again. Thank you from the bottom of my heart and assure you, I will take most excellent care of your kidney, like donating to effective charities. It's something where you can take a very small cost for yourself and help another person, a substantial amount,

1 (9m 9s):
How much money is in the effective altruism. I don't want to call it an industry business these days still

2 (9m 17s):
The complex is, is, is the noun I sometimes use. There's a lot of money. The vast majority of it comes from too, not just billionaires, but sort of Uber, billionaire households. One such household is Cura tuna and her husband, Dustin Moskovitz, Dustin Moskovitz is perhaps best known in the public as one of the roommates at Harvard of mark Zuckerberg, who helped him found Facebook cure. Tuna is a retired journalist who now works. Full-time on the philanthropic arm of her and Dustin's fortune.

8 (9m 55s):
We have so much more than we need to provide for ourselves and our family. And so giving the rest away seems like an obvious choice

2 (10m 5s):
As with all billionaires net worth varies a lot. There's is around 14 to $15 billion. The last time I checked the second mega billionaire is one person Sam Bankman freed.

9 (10m 18s):
No, I was thinking about working for some animal welfare organizations and they said, look, Sam likely, honestly, given your background would probably prefer your money to your time.

2 (10m 28s):
He runs a crypto exchange called FTX that has quickly become sort of one of the main places people buy and sell crypto

10 (10m 35s):
Fortune favors. The brave

2 (10m 39s):
He's worth a similar amount. Last I checked 12 to $15 billion. The John D and Catherine T MacArthur foundation, which is familiar to public radio listeners is, is worth about $6 billion. EA is worth about five of them. That's a lot of money. It really rapidly reshaped the philanthropic landscape in the us and not just the philanthropic landscape, but like Soros and like the Cokes tuna Moskovitz and Bankman freed are very interested in political donations,

1 (11m 12s):
Effective altruists are getting involved in politics like the sorosis and the Cokes, where and how are they spending their money?

2 (11m 20s):
The sort of effective altruists push into politics began kind of in earnest in 2016, out of a lot of really genuine panic about Donald Trump, the effect of altruists for a variety of reasons, worry a lot about worst case scenarios. And often think that a way to do good is to prevent worst case scenarios from happening because people aren't as concerned about them as they should be. And a populous leader with autocratic tendencies getting control of nuclear weapons seemed like a worst case scenario. So TuneIn mascots poured lots of money and overnight became one of the biggest donors to democratic campaigns and to sort of the effort to defeat Trump in 2016, they gave even more money in 2020.

2 (12m 4s):
And by that point Bankman freed had become a billionaire as well, and he gave a significant amount of money. But I think beyond general support for Democrats, something that appeals about politics to effective altruists and that his appeal to philanthropists before is that getting people you like elected and lobbying them when those people have controls over budgets that can span billions tens of billions, hundreds of billions of dollars. There's really good bang for your buck there Beyond some of these political priorities more recently, they've they've also been thinking more and trying to spend more money on effecting the very, very far future.

9 (12m 44s):
The vast majority of all people who will ever live have not yet been born. So, you know, my, my current thoughts are that in expected value, the future is what matters

1 (12m 58s):
Coming up next effective altruism takes a sort of weird turn toward the future.

Paycor (13m 14s):
This episode is brought to you by Paycor Paycor empowers leaders to build winning teams with Paycor leaders can recruit onboard and train employees, set goals and drive performance. If you're a leader, everyone depends on you. Who do leaders depend on Paycor, learn more at paycor.com/leaders.

Samsung Galaxy Z fold (13m 35s):
This episode is brought to you by Samsung unfold, the all new galaxy Z fold for and expand your world with flex mode. It stands on its own. So your hands free to get more done during calls and with multi window view, you can use up to three apps at the same time. Plus the edge to edge screen allows you to fully immerse yourself in your favorite games and shows visit samsung.com to learn more about galaxy Z fold for

13 (14m 6s):
You're listening to today, explains today, explain or check, explain, explain that point that

1 (14m 13s):
It's today explained I'm Noel king, Dylan Matthews, senior Vox correspondent, donator of kidney. We've been talking about doing good for and in the present, but there's an evolution in effective altruism. A really interesting one that has to do with caring about the very distant future. Tell me about that.

2 (14m 32s):
The other big sort of intellectual shift that's happened with NEA is away from with people, something that's called near termism and toward long-termism. We talked a lot earlier about global poverty, global health, making sure that people living right now in the poorest places on earth are better off. That was never the sole focus of the effective one. Other major focus has always been animals and factory farming in fact gets less attention just because in the general public, the idea that pigs or chickens being tortured in factory farms have comparative moral worth to, to human beings. Living lives of extreme desperation is controversial, but that's always been something that, that the major survey donors have cared about as well.

2 (15m 14s):
In the last five to six years, there's also been more focus on long-termism and the longterm future of the world generally. So the reasoning here is humans are a pretty young species. Sapiens emerged about 200 to 300,000 years ago. Mammal species like us typically live at least a million years. We're smarter than a lot of mammals. And so you might expect that to be even longer for us that implies that the vast majority of people who will ever live will live in the future

14 (15m 49s):
Future generations matter feature people matter and whatever you value and whether that's, you know, wellbeing or happiness, or maybe it's accomplishment, maybe it's great works of art. Maybe it's scientific discovery, almost all of whatever you value would be in the future of other than now, because the future just could be vast indeed.

2 (16m 9s):
And so one way that this concern manifested itself is trying to focus much more on preventing human extinction. And that's something that I think is intuitively good to a lot of people, but is under invested in that there's, there's really not that much money going into efforts to prevent nuclear war or the spread of nuclear weapons efforts to prevent pandemics efforts, to regulate new technologies. That could be really dangerous like AI. And so I think this kind of long-term his perspective pushed, EAs into caring more about those things. I think what's interesting about what we owe to the future, which is the new book by, by Wilma Casco, one of the founders of effective altruism and his is his kind of like treatise for long-termism is that he is trying to argue that caring about all these, these billions or trillions of humans who will live in the future.

2 (16m 57s):
Doesn't just mean trying to make sure that they exist at all, that we don't blow ourselves up before they can come to exist, but that we might have ways to, to make their lives better. From here.

14 (17m 9s):
There are enormous risks that we face or fats that we face that we need to manage. But if we do, then we can create a world that is flourishing and vibrant and wonderful for our grandkids, for their grandkids, for their grandkids.

1 (17m 26s):
Dylan, I don't have kids, although I care a lot about the world that my nieces and nephews are going to grow up in. I care a lot about the world that their kids will grow up in. And to be honest, my brain does not go much further than that. And so a question I would have for effective altruists like William McCaskill. Why should I be concerned about the life of someone who's living a hundred thousand years or 200,000 years from now?

2 (17m 51s):
The moral argument they would make is throughout human history. We've been kind of gradually expanding the people that we care about. There was a time when people cared a lot about their immediate family and not, not much beyond it there's time when they cared about sort of their tribe or their clan. And not much beyond that, the advent of religions and nations provided sort of another level to care about that you might care about fellow Christians or fellow Muslims or fellow Franks or fellow galls that that is gradually expanded

15 (18m 24s):
19:17 AM a 69 year drive by women or the right to vote is climaxed by this appeal to white house.

2 (18m 31s):
And it's expanded for, for men to start treating women as worthy of moral concern, to ask people in dominant racial groups, to care about other racial groups and, and do them as, as worthy of equal moral concern.

16 (18m 45s):
And we're as fast as the most sweeping civil rights bill ever to be written into the law and thus reaffirms the conception of equality for all men that began with Lincoln and the civil war 100 years ago.

2 (18m 57s):
And I think the argument is that people in the far future feel distance, but they might feel distant in the way that the groups that in the past were, were kind of dismissed, felt distant. And that if you care about people around the world right now, who you've never met, who may be radically different from you, that the difference in space might not be any more significant or any less significant than the difference in time between someone like you now, and someone like you centuries or millennia into the future. Maybe you buy that. Maybe you don't. But I think the argument is that a lot of progress in society has come from starting to take seriously groups that weren't taken seriously before.

2 (19m 40s):
And that ourselves in the future might be a group like that.

1 (19m 45s):
And I wonder if we could talk about what McCaskill refers to as plasticity or the idea that at a certain point systems become entrenched. And so if you're living in a time when the systems are not yet entrenched, you gotta be very careful. Can you talk a little bit about the bad future that could happen a hundred thousand years from now, if you and I decide today that we don't really care about much

2 (20m 11s):
Part of McCaskill's motivation is that you can look at examples thousands of years in the past and see how walk-in like that happened. Christianity has persisted a lot in the west Islam and Confucianism around the world have, have had millennial long influences. You can debate how positive or negative those have been, but it, it stands to reason that we could be locking in things right now. And so if you lock in norms around people not having any privacy from state surveillance that could have really negative long-term repercussions, if you walk in sort of anti-democratic norms, the ways happening in more and more large countries around the world and managed to have that persist as it did in the early days of states.

2 (20m 53s):
And when government was kind of a new thing, it took a while for, for democracy to, to really flourish. If that locks in for the next few thousand years, that could have really profound negative repercussions. The more out there thing that he worries about is AI is progressing very, very quickly. That could be a very powerful force for social control.

1 (21m 14s):
We are witnessing the rise of AI. If we mess it up, what I envision is Terminator too, right?

17 (21m 21s):
The survivors of the nuclear fire called the war judgment day. They lived only to face a new nightmare, the war against the machines,

1 (21m 34s):
The AI turns on us. It blows us all up. We live in a world where everything is xingjiang in China. We're being watched all the time. We're being imprisoned. If we do anything wrong, it seems like the long-term risk. We're saying, if we don't take care with AI, now we might lock ourselves into systems where Terminator two is not. I know this sounds insane, but Terminator two is not just a movie. It's the world that we live in

18 (21m 59s):
Alfie, no fate, but what we make,

2 (22m 5s):
Yeah, AI safety is, is an increasing focus of EAs. And long-term as DAS specifically,

9 (22m 10s):
It's sort of like cutting edge AI systems right now are mostly not changing the world, but these things grow exponentially. And you know, you project out 5, 10, 50, a hundred years. You may have some super powerful systems

2 (22m 25s):
And it can sound very out there. And it is to some degree. I think some of it is hard because we reach for metaphors that are at hand like, like Terminator, but it could be much weirder. There's been some proposals recently because Chinese and Russian nuclear response has gotten a lot faster too. Instead of having us second strike nuclear weapons, run through the white house, to have them controlled by an AI system that can respond faster. That's an interesting idea. And it is one that makes the quality of that AI system incredibly important to the survival of humanity. I think just as AI gets more advanced, we're going to turn more and more systems over to it. And we're going to do it without a full understanding of what those systems can do and what they can't do and ways in which they are, and aren't aligned with what we want them to do.

14 (23m 11s):
So an analogy is often given between like the lies of homosapiens from the perspective of the chimpanzees, where homosapiens were just smarter, they were able to work together. They just had these advantages. And that just means the chimpanzees just have very little say in how things go over the longterm, basically, no say, but that could happen with AI as well. We could be to the AI systems. What chimpanzees are to humans

1 (23m 36s):
Is this the first time in human history that we've thought of future people, like where does this fit in grand scheme of how humanity has thought about itself?

2 (23m 48s):
We're fairly early on in the process of thinking about this future in a secular way, The long-term future of the material corporeal earth was not. Super-important under a lot of Christian worldviews because this is a, an earthly limited plane. And your true life is in heaven with the Lord. And I think that worldview limited how you could think about the earthly plane as something that was of prime importance. The idea that that our fate on earth is really what matters does strike me as fairly new relative to the religious background of countries like the U S and UK.

2 (24m 34s):
So I don't think we should expect anyone in effective altruism or long termism to have anything like the final or best answers to these questions. What I find interesting is, is the choice to pose the questions and to be open, to being wrong about them. But to insist that they're important and worth asking

1 (25m 5s):
Today's show was produced by miles, Brian and edited by Matthew collect. It was engineered by a famous Shapiro, and it was fact checked by Laura bowler. I'm Noel king it's today explained If you like today explained, then you're probably a fan of unique and interesting stories, just like me and Sean and the rest of our team here.

Pocket (25m 44s):
So allow me to tell you about pocket pocket is a website and an app that finds thought provoking articles from trusted sources around the internet and puts them all in one place with pocket. You can save articles for later. You can even have articles read aloud to you. If that's your thing. They also have curated collections that are hand selected by pocket editors or a pocket partner in this case me for this episode, if you want to learn more about what we discussed on today's show, go to get pocket.com/vox and check out our effective altruism collection for more articles, podcast, book, and movie recommendations, and one very, very, very funny book review that gives you tons of context about the topic,

KiwiCo (26m 28s):
Looking for a great hands-on gift for the curious kids in your life, that tinker who can't stop exploring building and taking things apart. Kiwi COEs delivers super cool science technology and art projects for kids of all ages straight to your door every month, choose from nine different subscription lines focused on subjects like engineering, art, and design science of cooking, and more, every crate delivered has everything you need to complete the project in there. Seriously fun. Get 50% off your first month on any subscription line at QE code.com/vox, 50 that's Kiwi code.com/v O X five zero.