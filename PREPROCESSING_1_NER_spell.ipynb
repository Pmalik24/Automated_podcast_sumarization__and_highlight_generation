{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 200\n",
    "import numpy as np \n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now zipped in Summarization_and_preprocessig_dfs.zip and Summarization_and_preprocessig_dfs_2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['generated_transcripts'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_str_lens = df['generated_transcripts'].str.len().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(gen_str_lens).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['generated_transcripts'].iloc[:1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PREPROCESSING BEFORE SUMMARIZATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "import spacy\n",
    "from contractions import contractions_dict\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Spell checker\n",
    "spell = SpellChecker()\n",
    "\n",
    "# Loadng English tokenizer, tagger, parser, NER, and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Text Cleaning and Processing Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = contractions_dict\n",
    "\n",
    "\n",
    "def lower_dict(d):\n",
    "    return {k.lower(): v.lower() for k, v in d.items()}\n",
    "\n",
    "contraction_mapping = lower_dict(contractions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
    "                                      flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match, \n",
    "                        contraction_mapping.get(match.lower(), match)) # Default to match if not found\n",
    "        # Ensure the first character's case is preserved\n",
    "        expanded_contraction = first_char + expanded_contraction[1:] if expanded_contraction else match\n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    return expanded_text\n",
    "\n",
    "spell_check_cache = {}\n",
    "\n",
    "def correct_spellings_cached(text):\n",
    "    words = text.split()\n",
    "    corrected_words = []\n",
    "    for word in words:\n",
    "        if word not in spell_check_cache:\n",
    "            corrected_word = spell.correction(word) if spell.correction(word) else word\n",
    "            spell_check_cache[word] = corrected_word\n",
    "        else:\n",
    "            corrected_word = spell_check_cache[word]\n",
    "        corrected_words.append(corrected_word)\n",
    "    return ' '.join(corrected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentence_case(text):\n",
    "    \"\"\"Converts text to sentence case.\"\"\"\n",
    "    # Pattern to match sentence endings. Adjust as needed for abbreviations, etc.\n",
    "    sentence_endings = re.compile('(?<=[.!?]) +')\n",
    "    sentences = sentence_endings.split(text)\n",
    "    return ' '.join(sentence.capitalize() for sentence in sentences)\n",
    "\n",
    "def preprocess_text_NEW(text, contraction_mapping):\n",
    "    entity_placeholders = {}\n",
    "    doc = nlp(text)\n",
    "    processed_text = text\n",
    "    for ent in reversed(doc.ents):\n",
    "        placeholder = f\"<ENTITY_{ent.label_}_{ent.start_char}>\".lower()  # Lowercase the placeholder\n",
    "        entity_placeholders[placeholder] = ent.text\n",
    "        processed_text = processed_text[:ent.start_char] + placeholder + processed_text[ent.end_char:]\n",
    "    \n",
    "    processed_text = processed_text.lower()\n",
    "    processed_text = expand_contractions(processed_text, contraction_mapping)\n",
    "    processed_text = re.sub(r'\\b(?:' + '|'.join(['um', 'uh', 'you know', 'so', 'like']) + r')\\b', '', processed_text)\n",
    "    processed_text = re.sub(r'\\s+', ' ', processed_text)\n",
    "    processed_text = re.sub(r'\\s([?.!\",;](?:\\s|$))', r'\\1', processed_text)\n",
    "    processed_text = correct_spellings_cached(processed_text) # Uncomment to enable spell checking\n",
    "    processed_text = to_sentence_case(processed_text)\n",
    "    \n",
    "    for placeholder, original_text in entity_placeholders.items():\n",
    "        processed_text = processed_text.replace(placeholder, original_text.upper())\n",
    "    \n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dry JOHN SMITH's groundbreaking research on CRISPR gene editing at HARVARD UNIVERSITY was not that interesting\n",
      "From w b easy chico it is this america life i am nancy unlike filling in for era glass ti a show is a rerun a good on and i am gin a start with this story that i want a share it is little personal i was at MAC the make up store not the computers store and i was buying foundation which i almost never wear it is the make up you put all over your face to give yourself the pretend perfect skin and i asked the salesman for help finding the right color and he looked at me and he said almost you was thinking out loud he said your neck it is much more yellow than your face and then he turned away to start looking for the impossible color that would solve this problem of the yellow wrist next to the much more yellow and if you are thinking all this was just a sale's technique to invent a PROBLEM and then offer to fix it with more products i wish that that had been the case but this was not an upswell this was a free to cur the man really just seemed to be expressing his frustration at this stumper of my mismatched face and NECK\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = \"Dr. John Smith's groundbroking research on CRISPR gene editing at Harvard University wasn't that interesting\"\n",
    "y = \"FROM W B EASY CHICAGO IT'S THIS AMERICAN LIFE I'M NANCY UPDIKE FILLING IN FOR IRA GLASS TI DA SHOW IS A RERUN A GOOD ON AND I'M GIN A START WITH THIS STORY THAT I WANT A SHARE IT'S LITTLE PERSONAL I WAS AT MAC THE MAKE UP STORE NOT THE COMPUTERS STORE AND I WAS BUYING FOUNDATION WHICH I ALMOST NEVER WEAR IT'S THE MAKE UP YOU PUT ALL OVER YOUR FACE TO GIVE YOURSELF THE PRETEND PERFECT SKIN AND I ASKED THE SALESMAN FOR HELP FINDING THE RIGHT COLOR AND HE LOOKED AT ME AND HE SAID ALMOST LIKE YOU WAS THINKING OUT LOUD HE SAID YOUR NECK IT'S SO MUCH MORE YELLOW THAN YOUR FACE AND THEN HE TURNED AWAY TO START LOOKING FOR THE IMPOSSIBLE COLOR THAT WOULD SOLVE THIS PROBLEM OF THE YELLOW WRIHT NEXT TO THE SO MUCH MORE YELLOW AND IF YOU'RE THINKING ALL THIS WAS JUST A SALE'S TECHNIQUE TO INVENT A PROBLEM AND THEN OFFERD TO FIX IT WITH MORE PRODUCTS I WISH THAT THAT HAD BEEN THE CASE BUT THIS WAS NOT AN UPSELL THIS WAS A CREE TO CUR THE MAN REALLY JUST SEEMED TO BE EXPRESSING HIS FRUSTRATION AT THIS STUMPER OF MY MISMATCHED FACE AND NECK\"\n",
    "print(preprocess_text_NEW(x, contraction_mapping))\n",
    "print(preprocess_text_NEW(y, contraction_mapping))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# reconstructed_text = reconstruct_text_with_punctuation(y, pipe(y.lower()))\n",
    "\n",
    "# print(reconstructed_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['cleaned_generated_text'] = df['generated_trans'].apply(lambda x: preprocess_text_NEW(x, contraction_mapping))\n",
    "df['cleaned_generated_text'] = df['generated_transcripts'].apply(lambda x: preprocess_text_NEW(x, contraction_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = 'BEN_GENERATED_TRANS/39.txt'\n",
    "\n",
    "with open(sample_file, 'r') as file:\n",
    "    sample = file.read()\n",
    "\n",
    "with open('sample_preprocessed_text_6.txt_with_NER_and_Spell_Check', 'w') as out_file: \n",
    "    out_file.write(preprocess_text_NEW(sample, contraction_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('s_and_h_preprocess_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
